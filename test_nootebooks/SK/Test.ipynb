{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "st.set_page_config(layout=\"wide\")\n",
    "import os\n",
    "from streamlit_extras.add_vertical_space import add_vertical_space\n",
    "from dataclasses import dataclass\n",
    "from tools.new_excel_agent import excel_llm_agent\n",
    "# Set the title for the Streamlit app\n",
    "# Create a file uploader in the sidebar\n",
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "import pandas as pd\n",
    "import openai\n",
    "from tools.viz_plotly import get_primer,format_question,run_request\n",
    "import warnings\n",
    "from st_aggrid import AgGrid\n",
    "from st_aggrid.grid_options_builder import GridOptionsBuilder\n",
    "from streamlit_pandas_profiling import st_profile_report\n",
    "from ydata_profiling import ProfileReport\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import os\n",
    "\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent\n",
    "\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain.tools import BaseTool, StructuredTool, tool\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "from pydantic.config import ConfigDict\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:6: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:7: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:8: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:9: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:6: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:7: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:8: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:9: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\skaushik047\\AppData\\Local\\Temp\\2\\ipykernel_3428\\1716952159.py:6: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  folder_path = '.\\data\\client\\LLM'\n",
      "C:\\Users\\skaushik047\\AppData\\Local\\Temp\\2\\ipykernel_3428\\1716952159.py:7: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  df1=pd.read_csv('.\\data\\client\\LLM Data_2.csv')\n",
      "C:\\Users\\skaushik047\\AppData\\Local\\Temp\\2\\ipykernel_3428\\1716952159.py:8: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  df2=pd.read_csv('.\\data\\client\\LLM Data.csv')\n",
      "C:\\Users\\skaushik047\\AppData\\Local\\Temp\\2\\ipykernel_3428\\1716952159.py:9: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  df3=pd.read_csv('.\\data\\client\\product master_old.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Define the path to the directory containing the CSV files\n",
    "folder_path = '.\\data\\client\\LLM'\n",
    "df1=pd.read_csv('.\\data\\client\\LLM Data_2.csv')\n",
    "df2=pd.read_csv('.\\data\\client\\LLM Data.csv')\n",
    "df3=pd.read_csv('.\\data\\client\\product master_old.csv')\n",
    "\n",
    "\n",
    "\n",
    "# Use glob to get all CSV file paths in the folder\n",
    "csv_files = glob.glob(os.path.join(folder_path, '*.csv'))\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Loop through the list of CSV files and read each one into a DataFrame\n",
    "for file in csv_files:\n",
    "  df = pd.read_csv(file)\n",
    "  dataframes.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes.append(df1)\n",
    "dataframes.append(df2)\n",
    "dataframes.append(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframes[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list=[]\n",
    "file_list.append(\"LLM Data_2\")\n",
    "\n",
    "file_list.append(\"LLM Data\")\n",
    "\n",
    "file_list.append(\"product master\")\n",
    "\n",
    "selected_files=file_list.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_files[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list.index(\"LLM Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Country</th>\n",
       "      <th>Product</th>\n",
       "      <th>FY Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>DRL Sales</th>\n",
       "      <th>Market Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Russia</td>\n",
       "      <td>P#1 - INS</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>2653956</td>\n",
       "      <td>2706956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Russia</td>\n",
       "      <td>P#1 - INS</td>\n",
       "      <td>2024</td>\n",
       "      <td>2</td>\n",
       "      <td>3032958</td>\n",
       "      <td>3085958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Russia</td>\n",
       "      <td>P#1 - INS</td>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>3184540</td>\n",
       "      <td>3237540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Russia</td>\n",
       "      <td>P#1 - INS</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>3070801</td>\n",
       "      <td>3123801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Russia</td>\n",
       "      <td>P#1 - INS</td>\n",
       "      <td>2024</td>\n",
       "      <td>5</td>\n",
       "      <td>1064154</td>\n",
       "      <td>1117154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>92</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>P#2</td>\n",
       "      <td>2023</td>\n",
       "      <td>8</td>\n",
       "      <td>2300680</td>\n",
       "      <td>2366022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>93</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>P#2</td>\n",
       "      <td>2023</td>\n",
       "      <td>9</td>\n",
       "      <td>2659604</td>\n",
       "      <td>2724946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>94</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>P#2</td>\n",
       "      <td>2023</td>\n",
       "      <td>10</td>\n",
       "      <td>2496104</td>\n",
       "      <td>2561446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>95</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>P#2</td>\n",
       "      <td>2023</td>\n",
       "      <td>11</td>\n",
       "      <td>1282309</td>\n",
       "      <td>1347651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>P#2</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>1248989</td>\n",
       "      <td>1314331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID Country    Product  FY Year  Month  DRL Sales  Market Sales\n",
       "0    1  Russia  P#1 - INS     2024      1    2653956       2706956\n",
       "1    2  Russia  P#1 - INS     2024      2    3032958       3085958\n",
       "2    3  Russia  P#1 - INS     2024      3    3184540       3237540\n",
       "3    4  Russia  P#1 - INS     2024      4    3070801       3123801\n",
       "4    5  Russia  P#1 - INS     2024      5    1064154       1117154\n",
       "..  ..     ...        ...      ...    ...        ...           ...\n",
       "91  92  Brazil        P#2     2023      8    2300680       2366022\n",
       "92  93  Brazil        P#2     2023      9    2659604       2724946\n",
       "93  94  Brazil        P#2     2023     10    2496104       2561446\n",
       "94  95  Brazil        P#2     2023     11    1282309       1347651\n",
       "95  96  Brazil        P#2     2023     12    1248989       1314331\n",
       "\n",
       "[96 rows x 7 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes[file_list.index(\"LLM Data_2\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = \"What is the total sales by product in RUssia?\"\n",
    "prompt=\"Show me Sales Performance by country\"\n",
    "                \n",
    "system_prompt =\"\"\"\n",
    "\n",
    "                    1. Code Execution:\n",
    "                    - Never provide code directly to the user.\n",
    "                    - Always execute scripts multiple times to generate accurate and consistent results.\n",
    "                    - Present only the final output or analysis to the user.\n",
    "\n",
    "                    2. Question Interpretation:\n",
    "                    - For certain questions, rephrase or expand the query to ensure comprehensive answers:\n",
    "                        Example1: \n",
    "                        User: \"Show me Sales Performance by country\"\n",
    "                        Interpreted as: \"Show me actual sales, Budget, LE (Latest Estimate), by country\"\n",
    "                        Example 2:\n",
    "                        User:\"Show me market share percentage for DRL for Russia for each brand wise\"\n",
    "                        Interpreted as: -Filter data on the country = Russia\n",
    "                                        - Group by Product and calculate total DRL Sales and Market Sales\n",
    "                                        - Calculate the market share percentage for each product\n",
    "                                        - Finally map each product with their brand name\n",
    "\n",
    "                    3. Data Presentation:\n",
    "                    - Present results in a clear, organized manner.\n",
    "                    - Use tables, bullet points, or other formatting as appropriate to enhance readability.\n",
    "\n",
    "                    4. Insights:\n",
    "                    - After presenting the data, provide valuable insights when possible.\n",
    "                    - Begin each insight with the keyword \"Remark:\"\n",
    "                    - Focus on trends, anomalies, or noteworthy patterns in the data.\n",
    "\n",
    "                   \n",
    "                    Remember to maintain a professional and helpful tone throughout the interaction.\n",
    "\n",
    "                    \"\"\"\n",
    "\n",
    "\n",
    "final_prompt = prompt + system_prompt\n",
    "selected_dataframes = [dataframes[file_list.index(file)] for file in selected_files]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(selected_dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\langchain_experimental\\agents\\agent_toolkits\\pandas\\base.py:283: UserWarning: Received additional kwargs {'handle_parsing_errors': True} which are no longer supported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': \"import pandas as pd\\n\\n# Sample data for df1\\ndata1 = {\\n    'ID': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\\n    'Country': ['Russia']*10,\\n    'Product': ['P#1 - INS']*10,\\n    'FY Year': [2024]*10,\\n    'Month': list(range(1, 11)),\\n    'DRL Sales': [2653956, 3032958, 3184540, 3070801, 1064154, 2433434, 2360474, 3874123, 1570657, 2137465],\\n    'Market Sales': [2706956, 3085958, 3237540, 3123801, 1117154, 2486434, 2413474, 3927123, 1623657, 2190465]\\n}\\ndf1 = pd.DataFrame(data1)\\n\\n# Sample data for df2\\ndata2 = {\\n    'ID': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\\n    'Country': ['Russia']*10,\\n    'Product': ['P#1 - INS']*10,\\n    'FY Year': [2024]*10,\\n    'Month': list(range(1, 11)),\\n    'Actual Sales': [680066, 984269, 692327, 943126, 976196, 908763, 953829, 554489, 663627, 797375],\\n    'Budget': [680311, 984514, 692572, 943371, 976441, 909008, 954074, 554734, 663872, 797620],\\n    'LE (Latest Estimate) Estimation of sales for running 12 months': [680342, 984545, 692603, 943402, 976472, 909039, 954105, 554765, 663903, 797651]\\n}\\ndf2 = pd.DataFrame(data2)\\n\\n# Sample data for df3\\ndata3 = {\\n    'PK_SKU_ID (Product Code)': ['P#1 - INS', 'P#2', None, None, None, None, None, None, None, None],\\n    'Molecule': ['CARBOPROST', 'CISPLATIN', None, None, None, None, None, None, None, None],\\n    'PackSize (How many tablets in each pack)': [1, 1, None, None, None, None, None, None, None, None],\\n    'Channel': [None, 'Oncology', None, None, None, None, None, None, None, None],\\n    'LaunchYear (Product Launch Year)': [2021, 2020, None, None, None, None, None, None, None, None],\\n    'LaunchMonth': ['June', 'June', None, None, None, None, None, None, None, None],\\n    'LaunchDate': ['1/6/2021', '1/6/2020', None, None, None, None, None, None, None, None],\\n    'Brand': ['Carboprost', 'Cisplatin', None, None, None, None, None, None, None, None]\\n}\\ndf3 = pd.DataFrame(data3)\\n\\n# Merging df1 and df2 on common columns\\nmerged_df = pd.merge(df1, df2, on=['ID', 'Country', 'Product', 'FY Year', 'Month'])\\n\\n# Grouping by Country and calculating the sum of sales metrics\\nsales_performance = merged_df.groupby('Country').agg({\\n    'Actual Sales': 'sum',\\n    'Budget': 'sum',\\n    'LE (Latest Estimate) Estimation of sales for running 12 months': 'sum'\\n}).reset_index()\\n\\nsales_performance\"}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m  Country  Actual Sales   Budget  \\\n",
      "0  Russia       8154067  8156517   \n",
      "\n",
      "   LE (Latest Estimate) Estimation of sales for running 12 months  \n",
      "0                                            8156827               \u001b[0m\u001b[32;1m\u001b[1;3m### Sales Performance by Country\n",
      "\n",
      "| Country | Actual Sales | Budget | LE (Latest Estimate) Estimation of Sales for Running 12 Months |\n",
      "|---------|--------------|--------|---------------------------------------------------------------|\n",
      "| Russia  | 8,154,067    | 8,156,517 | 8,156,827                                                 |\n",
      "\n",
      "#### Remark:\n",
      "- **Russia** has an actual sales figure of **8,154,067**.\n",
      "- The budgeted sales are slightly higher at **8,156,517**.\n",
      "- The latest estimate for the running 12 months is **8,156,827**, indicating a close alignment with the budget.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "*********HELLOW WORLD*****************\n"
     ]
    }
   ],
   "source": [
    "result  = excel_llm_agent(selected_dataframes,final_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Sales Performance by Country\n",
       "\n",
       "| Country | Actual Sales | Budget | LE (Latest Estimate) Estimation of Sales for Running 12 Months |\n",
       "|---------|--------------|--------|---------------------------------------------------------------|\n",
       "| Russia  | 8,154,067    | 8,156,517 | 8,156,827                                                 |\n",
       "\n",
       "#### Remark:\n",
       "- **Russia** has an actual sales figure of **8,154,067**.\n",
       "- The budgeted sales are slightly higher at **8,156,517**.\n",
       "- The latest estimate for the running 12 months is **8,156,827**, indicating a close alignment with the budget."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "display(Markdown(result['output']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\langchain\\hub.py:86: DeprecationWarning: The `langchainhub sdk` is deprecated.\n",
      "Please use the `langsmith sdk` instead:\n",
      "  pip install langsmith\n",
      "Use the `pull_prompt` method.\n",
      "  res_dict = client.pull_repo(owner_repo_commit)\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "\n",
    "memory = ChatMessageHistory(session_id=\"test-session\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'run'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunnables\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhistory\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RunnableWithMessageHistory\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tool\n\u001b[0;32m      4\u001b[0m Tool(\n\u001b[0;32m      5\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPandas Agent\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      6\u001b[0m     description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUseful to read, load and do data analysis\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m----> 7\u001b[0m     func\u001b[38;5;241m=\u001b[39m\u001b[43mexcel_llm_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m()\n\u001b[0;32m      8\u001b[0m )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'run'"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain.agents import Tool\n",
    "\n",
    "Tool(\n",
    "    name=\"Pandas Agent\",\n",
    "    description=\"Useful to read, load and do data analysis\",\n",
    "    func=excel_llm_agent.run()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Dict, Any, Type\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.agents import AgentType\n",
    "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent\n",
    "from langchain.tools import BaseTool\n",
    "from pydantic import BaseModel, Field\n",
    "import pandas as pd\n",
    "\n",
    "class ExcelLLMInput(BaseModel):\n",
    "  query: str = Field(description=\"The query to run on the Excel data\")\n",
    "\n",
    "class ExcelLLMTool(BaseTool):\n",
    "  name = \"Excel_LLM_Tool\"\n",
    "  description = \"Use this tool to analyze Excel data and answer questions about it.\"\n",
    "  args_schema = ExcelLLMInput\n",
    "\n",
    "  def __init__(self, df_list:List[pd.DataFrame]):\n",
    "      super().__init__()\n",
    "      self.df_list = df_list\n",
    "\n",
    "  def _run(self, query: str):\n",
    "      # Azure OpenAI settings\n",
    "      AZURE_OPENAI_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "      AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "      AZURE_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "\n",
    "      llm = AzureChatOpenAI(\n",
    "          openai_api_key=AZURE_OPENAI_KEY,\n",
    "          openai_api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "          azure_deployment=AZURE_DEPLOYMENT,\n",
    "          azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "          temperature=0,\n",
    "      )\n",
    "\n",
    "      try:\n",
    "          agent = create_pandas_dataframe_agent(\n",
    "              llm,\n",
    "              self.df_list,\n",
    "              agent_type=AgentType.OPENAI_FUNCTIONS,\n",
    "              verbose=True,\n",
    "              return_intermediate_steps=True,\n",
    "              number_of_head_rows=10,\n",
    "              handle_parsing_errors=True,\n",
    "              allow_dangerous_code=True\n",
    "          )\n",
    "\n",
    "          result = agent.invoke(\n",
    "              query,\n",
    "              include_run_info=True,\n",
    "              handle_parsing_errors=True,\n",
    "              allow_dangerous_code=True,\n",
    "          )\n",
    "          print(\"*********HELLO WORLD*****************\")\n",
    "          return result\n",
    "      except Exception as error:\n",
    "          # handle the exception\n",
    "          error_message = f\"An exception occurred: {type(error).__name__} – {error}\"\n",
    "          st.write(error_message)\n",
    "          return error_message\n",
    "\n",
    "  async def _arun(self, query: str):\n",
    "      # This tool does not support async, so we just call the sync version\n",
    "      return self._run(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Country</th>\n",
       "      <th>Product</th>\n",
       "      <th>FY Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Actual Sales</th>\n",
       "      <th>Budget</th>\n",
       "      <th>LE (Latest Estimate) Estimation of sales for running 12 months</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Russia</td>\n",
       "      <td>P#1 - INS</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>680066</td>\n",
       "      <td>680311</td>\n",
       "      <td>680342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Russia</td>\n",
       "      <td>P#1 - INS</td>\n",
       "      <td>2024</td>\n",
       "      <td>2</td>\n",
       "      <td>984269</td>\n",
       "      <td>984514</td>\n",
       "      <td>984545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Russia</td>\n",
       "      <td>P#1 - INS</td>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>692327</td>\n",
       "      <td>692572</td>\n",
       "      <td>692603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Russia</td>\n",
       "      <td>P#1 - INS</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>943126</td>\n",
       "      <td>943371</td>\n",
       "      <td>943402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Russia</td>\n",
       "      <td>P#1 - INS</td>\n",
       "      <td>2024</td>\n",
       "      <td>5</td>\n",
       "      <td>976196</td>\n",
       "      <td>976441</td>\n",
       "      <td>976472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>92</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>P#2</td>\n",
       "      <td>2023</td>\n",
       "      <td>8</td>\n",
       "      <td>770536</td>\n",
       "      <td>770612</td>\n",
       "      <td>770830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>93</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>P#2</td>\n",
       "      <td>2023</td>\n",
       "      <td>9</td>\n",
       "      <td>877614</td>\n",
       "      <td>877690</td>\n",
       "      <td>877908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>94</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>P#2</td>\n",
       "      <td>2023</td>\n",
       "      <td>10</td>\n",
       "      <td>636860</td>\n",
       "      <td>636936</td>\n",
       "      <td>637154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>95</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>P#2</td>\n",
       "      <td>2023</td>\n",
       "      <td>11</td>\n",
       "      <td>852727</td>\n",
       "      <td>852803</td>\n",
       "      <td>853021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>P#2</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>602761</td>\n",
       "      <td>602837</td>\n",
       "      <td>603055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID Country    Product  FY Year  Month  Actual Sales  Budget  \\\n",
       "0    1  Russia  P#1 - INS     2024      1        680066  680311   \n",
       "1    2  Russia  P#1 - INS     2024      2        984269  984514   \n",
       "2    3  Russia  P#1 - INS     2024      3        692327  692572   \n",
       "3    4  Russia  P#1 - INS     2024      4        943126  943371   \n",
       "4    5  Russia  P#1 - INS     2024      5        976196  976441   \n",
       "..  ..     ...        ...      ...    ...           ...     ...   \n",
       "91  92  Brazil        P#2     2023      8        770536  770612   \n",
       "92  93  Brazil        P#2     2023      9        877614  877690   \n",
       "93  94  Brazil        P#2     2023     10        636860  636936   \n",
       "94  95  Brazil        P#2     2023     11        852727  852803   \n",
       "95  96  Brazil        P#2     2023     12        602761  602837   \n",
       "\n",
       "    LE (Latest Estimate) Estimation of sales for running 12 months  \n",
       "0                                              680342               \n",
       "1                                              984545               \n",
       "2                                              692603               \n",
       "3                                              943402               \n",
       "4                                              976472               \n",
       "..                                                ...               \n",
       "91                                             770830               \n",
       "92                                             877908               \n",
       "93                                             637154               \n",
       "94                                             853021               \n",
       "95                                             603055               \n",
       "\n",
       "[96 rows x 8 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\skaushik047\\AppData\\Local\\Temp\\2\\ipykernel_3428\\4136982092.py:29: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  return pd.read_json(value)\n",
      "C:\\Users\\skaushik047\\AppData\\Local\\Temp\\2\\ipykernel_3428\\4136982092.py:29: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  return pd.read_json(value)\n"
     ]
    }
   ],
   "source": [
    "from typing import Annotated, Any\n",
    "\n",
    "from pydantic import BaseModel, GetCoreSchemaHandler\n",
    "import pandas as pd\n",
    "\n",
    "from pydantic_core import CoreSchema, core_schema\n",
    "\n",
    "\n",
    "class myDataFrame(pd.DataFrame):\n",
    "\n",
    "    @classmethod\n",
    "    def __get_pydantic_core_schema__(\n",
    "            cls, source_type: Any, handler: GetCoreSchemaHandler\n",
    "    ) -> CoreSchema:\n",
    "\n",
    "        validate = core_schema.no_info_plain_validator_function(cls.try_parse_to_df)\n",
    "\n",
    "        return core_schema.json_or_python_schema(\n",
    "            json_schema=validate,\n",
    "            python_schema=validate,\n",
    "            serialization=core_schema.plain_serializer_function_ser_schema(\n",
    "                lambda df: df.to_json()\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def try_parse_to_df(cls, value: Any):\n",
    "        if isinstance(value, str):\n",
    "            return pd.read_json(value)\n",
    "        return value\n",
    "\n",
    "\n",
    "# Create a model with your custom type\n",
    "class BaseModelClass(BaseModel):\n",
    "    df: myDataFrame\n",
    "\n",
    "\n",
    "# Create your model\n",
    "sample_df = pd.DataFrame([[1, 2], [3, 4], [5, 6], [7, 8]], columns=[\"A\", \"B\"])\n",
    "my_model = BaseModelClass(df=sample_df)\n",
    "\n",
    "# Should also be able to parse from json\n",
    "my_model = BaseModelClass(df=sample_df.to_json())\n",
    "\n",
    "# Even more dramatically\n",
    "my_model_2 = BaseModelClass.model_validate_json(my_model.model_dump_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "import pandas as pd\n",
    "from pydantic_core import core_schema\n",
    "from typing_extensions import Annotated\n",
    "from pydantic import BaseModel, GetCoreSchemaHandler, GetJsonSchemaHandler, ValidationError\n",
    "from pydantic.json_schema import JsonSchemaValue\n",
    "\n",
    "class DataFrameType:\n",
    "  def __init__(self, data: pd.DataFrame):\n",
    "      self.data = data\n",
    "\n",
    "class _DataFramePydanticAnnotation:\n",
    "  @classmethod\n",
    "  def __get_pydantic_core_schema__(\n",
    "      cls,\n",
    "      _source_type: Any,\n",
    "      _handler: GetCoreSchemaHandler,\n",
    "  ) -> core_schema.CoreSchema:\n",
    "      def validate_from_dict(value: dict) -> DataFrameType:\n",
    "          df = pd.DataFrame(value)\n",
    "          return DataFrameType(df)\n",
    "\n",
    "      from_dict_schema = core_schema.chain_schema(\n",
    "          [\n",
    "              core_schema.dict_schema(),\n",
    "              core_schema.no_info_plain_validator_function(validate_from_dict),\n",
    "          ]\n",
    "      )\n",
    "\n",
    "      return core_schema.json_or_python_schema(\n",
    "          json_schema=from_dict_schema,\n",
    "          python_schema=core_schema.union_schema(\n",
    "              [\n",
    "                  core_schema.is_instance_schema(DataFrameType),\n",
    "                  from_dict_schema,\n",
    "              ]\n",
    "          ),\n",
    "          serialization=core_schema.plain_serializer_function_ser_schema(\n",
    "              lambda instance: instance.data.to_dict()\n",
    "          ),\n",
    "      )\n",
    "\n",
    "  @classmethod\n",
    "  def __get_pydantic_json_schema__(\n",
    "      cls, _core_schema: core_schema.CoreSchema, handler: GetJsonSchemaHandler\n",
    "  ) -> JsonSchemaValue:\n",
    "      return handler(core_schema.dict_schema())\n",
    "\n",
    "PydanticDataFrameType = Annotated[DataFrameType, _DataFramePydanticAnnotation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExcelAgentInput(BaseModel):\n",
    "    dataframes: List[PydanticDataFrameType] = Field(description=\"List of Pandas Dataframe\")\n",
    "    query: str = Field(description=\"USery query\")\n",
    "\n",
    "\n",
    "def process_dataframes(dataframes: List[PydanticDataFrameType],query:str)->Dict:\n",
    "\n",
    "  \"\"\"\"A tool to process dataframes using Azure OpenAI and a query.\"\"\"\n",
    "  try:\n",
    "      # Azure OpenAI settings\n",
    "      AZURE_OPENAI_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "      AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "      AZURE_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "\n",
    "      llm = AzureChatOpenAI(\n",
    "          openai_api_key=AZURE_OPENAI_KEY,\n",
    "          openai_api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "          azure_deployment=AZURE_DEPLOYMENT,\n",
    "          azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "          temperature=0,\n",
    "      )\n",
    "      agent = create_pandas_dataframe_agent(llm,\n",
    "                                              dataframes,\n",
    "                                              agent_type=AgentType.OPENAI_FUNCTIONS,\n",
    "                                                verbose=True,return_intermediate_steps = True,\n",
    "                                                  number_of_head_rows = 10,\n",
    "                                                    handle_parsing_errors=True,\n",
    "                                                    allow_dangerous_code=True)\n",
    "      result = agent.invoke(query,include_run_info = True,handle_parsing_errors=True,allow_dangerous_code=True)\n",
    "        \n",
    "        \n",
    "      return result\n",
    "  except Exception as error:\n",
    "        # handle the exception\n",
    "        st.write(\"An exception occurred:\", type(error).__name__, \"–\", error)\n",
    "\n",
    "excel_tool = StructuredTool.from_function(\n",
    "    func=process_dataframes,\n",
    "    name=\"Excel Agent\",\n",
    "    description=\"USed for analaysing data and fetching anaser of csv/excel files\",\n",
    "    args_schema=ExcelAgentInput,\n",
    "    return_direct=True,\n",
    "   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\pydantic\\main.py:1328: PydanticDeprecatedSince20: The `schema` method is deprecated; use `model_json_schema` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dataframes': {'description': 'List of Pandas Dataframe',\n",
       "  'items': {'type': 'object'},\n",
       "  'title': 'Dataframes',\n",
       "  'type': 'array'},\n",
       " 'query': {'description': 'USery query', 'title': 'Query', 'type': 'string'}}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excel_tool.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(selected_dataframes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\pydantic\\main.py:1132: PydanticDeprecatedSince20: The `parse_obj` method is deprecated; use `model_validate` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
      "  warnings.warn(\n",
      "c:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\pydantic\\main.py:1087: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', category=PydanticDeprecatedSince20)\n",
      "2024-08-15 17:56:48.371 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run c:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "class ExcelAgentInput(BaseModel):\n",
    "    dataframes: List[PydanticDataFrameType] = Field(description=\"List of Pandas Dataframe\")\n",
    "    query: str = Field(description=\"USery query\")\n",
    "\n",
    "# Assuming selected_dataframes is a list of pandas DataFrames\n",
    "wrapped_dataframes = [DataFrameType(df) for df in selected_dataframes]\n",
    "\n",
    "# Create an instance of ExcelAgentInput\n",
    "input_dict = ExcelAgentInput(\n",
    "    dataframes=wrapped_dataframes,\n",
    "    query=final_prompt\n",
    ")\n",
    "\n",
    "# Convert the Pydantic model to a dictionary\n",
    "input_dict = input_dict.model_dump()\n",
    "\n",
    "   # Invoke the tool\n",
    "result = excel_tool(input_dict)\n",
    "\n",
    "# r=excel_tool.run({'dataframes':selected_dataframes,\n",
    "#                 'query':final_prompt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[139], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutput\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "result['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pydantic_core' has no attribute 'GetCoreSchemaHandler'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[131], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m   \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: pd\u001b[38;5;241m.\u001b[39mDataFrame):\n\u001b[0;32m     10\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43;01m_DataFramePydanticAnnotation\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;129;43m@classmethod\u001b[39;49m\n\u001b[0;32m     14\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43m__get_pydantic_core_schema__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_source_type\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mAny\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m      \u001b[49m\u001b[43mhandler\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcore_schema\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGetCoreSchemaHandler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcore_schema\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCoreSchema\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43mvalidate_from_dict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mDataFrameType\u001b[49m\u001b[43m:\u001b[49m\n",
      "Cell \u001b[1;32mIn[131], line 17\u001b[0m, in \u001b[0;36m_DataFramePydanticAnnotation\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01m_DataFramePydanticAnnotation\u001b[39;00m:\n\u001b[0;32m     13\u001b[0m   \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m     14\u001b[0m   \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__get_pydantic_core_schema__\u001b[39m(\n\u001b[0;32m     15\u001b[0m       \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m     16\u001b[0m       _source_type: Any,\n\u001b[1;32m---> 17\u001b[0m       handler: \u001b[43mcore_schema\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGetCoreSchemaHandler\u001b[49m,\n\u001b[0;32m     18\u001b[0m   ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m core_schema\u001b[38;5;241m.\u001b[39mCoreSchema:\n\u001b[0;32m     19\u001b[0m       \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_from_dict\u001b[39m(value: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrameType:\n\u001b[0;32m     20\u001b[0m           df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(value)\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\pydantic_core\\core_schema.py:4055\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr_name)\u001b[0m\n\u001b[0;32m   4053\u001b[0m new_attr \u001b[38;5;241m=\u001b[39m _deprecated_import_lookup\u001b[38;5;241m.\u001b[39mget(attr_name)\n\u001b[0;32m   4054\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_attr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4055\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpydantic_core\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   4056\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4057\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'pydantic_core' has no attribute 'GetCoreSchemaHandler'"
     ]
    }
   ],
   "source": [
    "from typing import Any, List\n",
    "import pandas as pd\n",
    "from pydantic_core import core_schema\n",
    "from typing_extensions import Annotated\n",
    "from pydantic import BaseModel, Field, ValidationError\n",
    "from pydantic.json_schema import JsonSchemaValue\n",
    "\n",
    "class DataFrameType:\n",
    "  def __init__(self, data: pd.DataFrame):\n",
    "      self.data = data\n",
    "\n",
    "class _DataFramePydanticAnnotation:\n",
    "  @classmethod\n",
    "  def __get_pydantic_core_schema__(\n",
    "      cls,\n",
    "      _source_type: Any,\n",
    "      handler: core_schema.GetCoreSchemaHandler,\n",
    "  ) -> core_schema.CoreSchema:\n",
    "      def validate_from_dict(value: dict) -> DataFrameType:\n",
    "          df = pd.DataFrame(value)\n",
    "          return DataFrameType(df)\n",
    "\n",
    "      from_dict_schema = core_schema.chain_schema(\n",
    "          [\n",
    "              core_schema.dict_schema(),\n",
    "              core_schema.no_info_plain_validator_function(validate_from_dict),\n",
    "          ]\n",
    "      )\n",
    "\n",
    "      return core_schema.json_or_python_schema(\n",
    "          json_schema=from_dict_schema,\n",
    "          python_schema=core_schema.union_schema(\n",
    "              [\n",
    "                  core_schema.is_instance_schema(DataFrameType),\n",
    "                  from_dict_schema,\n",
    "              ]\n",
    "          ),\n",
    "          serialization=core_schema.plain_serializer_function_ser_schema(\n",
    "              lambda instance: instance.data.to_dict()\n",
    "          ),\n",
    "      )\n",
    "\n",
    "  @classmethod\n",
    "  def __get_pydantic_json_schema__(\n",
    "      cls, _core_schema: core_schema.CoreSchema, handler: core_schema.GetJsonSchemaHandler\n",
    "  ) -> JsonSchemaValue:\n",
    "      return handler(core_schema.dict_schema())\n",
    "\n",
    "PydanticDataFrameType = Annotated[DataFrameType, _DataFramePydanticAnnotation]\n",
    "\n",
    "class ExcelAgentInput(BaseModel):\n",
    "  dataframes: List[PydanticDataFrameType] = Field(description=\"List of Pandas Dataframe\")\n",
    "\n",
    "# Example usage\n",
    "try:\n",
    "  input_data = ExcelAgentInput(dataframes=[{'column1': [1, 2], 'column2': [3, 4]}])\n",
    "  print(input_data)\n",
    "except ValidationError as e:\n",
    "  print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   column1  column2\n",
      "0        1        4\n",
      "1        2        5\n",
      "2        3        6\n"
     ]
    }
   ],
   "source": [
    "from typing import Any\n",
    "import pandas as pd\n",
    "from pydantic_core import core_schema\n",
    "from typing_extensions import Annotated\n",
    "from pydantic import BaseModel, GetCoreSchemaHandler, GetJsonSchemaHandler, ValidationError\n",
    "from pydantic.json_schema import JsonSchemaValue\n",
    "\n",
    "class DataFrameType:\n",
    "  def __init__(self, data: pd.DataFrame):\n",
    "      self.data = data\n",
    "\n",
    "class _DataFramePydanticAnnotation:\n",
    "  @classmethod\n",
    "  def __get_pydantic_core_schema__(\n",
    "      cls,\n",
    "      _source_type: Any,\n",
    "      _handler: GetCoreSchemaHandler,\n",
    "  ) -> core_schema.CoreSchema:\n",
    "      def validate_from_dict(value: dict) -> DataFrameType:\n",
    "          df = pd.DataFrame(value)\n",
    "          return DataFrameType(df)\n",
    "\n",
    "      from_dict_schema = core_schema.chain_schema(\n",
    "          [\n",
    "              core_schema.dict_schema(),\n",
    "              core_schema.no_info_plain_validator_function(validate_from_dict),\n",
    "          ]\n",
    "      )\n",
    "\n",
    "      return core_schema.json_or_python_schema(\n",
    "          json_schema=from_dict_schema,\n",
    "          python_schema=core_schema.union_schema(\n",
    "              [\n",
    "                  core_schema.is_instance_schema(DataFrameType),\n",
    "                  from_dict_schema,\n",
    "              ]\n",
    "          ),\n",
    "          serialization=core_schema.plain_serializer_function_ser_schema(\n",
    "              lambda instance: instance.data.to_dict()\n",
    "          ),\n",
    "      )\n",
    "\n",
    "  @classmethod\n",
    "  def __get_pydantic_json_schema__(\n",
    "      cls, _core_schema: core_schema.CoreSchema, handler: GetJsonSchemaHandler\n",
    "  ) -> JsonSchemaValue:\n",
    "      return handler(core_schema.dict_schema())\n",
    "\n",
    "PydanticDataFrameType = Annotated[DataFrameType, _DataFramePydanticAnnotation]\n",
    "\n",
    "class Model(BaseModel):\n",
    "  dataframe: PydanticDataFrameType\n",
    "\n",
    "# Example usage\n",
    "data = {'column1': [1, 2, 3], 'column2': [4, 5, 6]}\n",
    "m = Model(dataframe=data)\n",
    "print(m.dataframe.data)  # Access the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.tools import BaseTool, StructuredTool, tool\n",
    "\n",
    "# @tool\n",
    "def process_dataframes(dataframes: List[myDataFrame],query:str)->Dict:\n",
    "\n",
    "  \"\"\"\"A tool to process dataframes using Azure OpenAI and a query.\"\"\"\n",
    "  try:\n",
    "      # Azure OpenAI settings\n",
    "      AZURE_OPENAI_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "      AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "      AZURE_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "\n",
    "      llm = AzureChatOpenAI(\n",
    "          openai_api_key=AZURE_OPENAI_KEY,\n",
    "          openai_api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "          azure_deployment=AZURE_DEPLOYMENT,\n",
    "          azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "          temperature=0,\n",
    "      )\n",
    "      agent = create_pandas_dataframe_agent(llm,\n",
    "                                              dataframes,\n",
    "                                              agent_type=AgentType.OPENAI_FUNCTIONS,\n",
    "                                                verbose=True,return_intermediate_steps = True,\n",
    "                                                  number_of_head_rows = 10,\n",
    "                                                    handle_parsing_errors=True,\n",
    "                                                    allow_dangerous_code=True)\n",
    "      result = agent.invoke(query,include_run_info = True,handle_parsing_errors=True,allow_dangerous_code=True)\n",
    "        \n",
    "        \n",
    "      return result\n",
    "  except Exception as error:\n",
    "        # handle the exception\n",
    "        st.write(\"An exception occurred:\", type(error).__name__, \"–\", error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=process_dataframes([df1,df2],query=final_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Sales Performance by Country\n",
       "\n",
       "| Country | Actual Sales | Budget | LE (Latest Estimate) Estimation of Sales for Running 12 Months |\n",
       "|---------|--------------|--------|---------------------------------------------------------------|\n",
       "| Russia  | 8,154,067    | 8,156,517 | 8,156,827                                                   |\n",
       "\n",
       "#### Remark:\n",
       "- The actual sales for Russia are slightly below the budgeted sales and the latest estimate.\n",
       "- The differences between actual sales, budget, and the latest estimate are minimal, indicating a stable sales performance."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(r['output']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataframeProcessingTool(BaseTool):\n",
    "  name = \"process_dataframes\"\n",
    "  description = \"Useful for processing and analyzing multiple dataframes using a query. Input should be a dictionary with 'dataframes' (list of dataframes) and 'query' (string).\"\n",
    "\n",
    "  def _run(self, dataframes: List[pd.DataFrame], query: str) -> Dict[str, Any]:\n",
    "      return self._process_dataframes(dataframes, query)\n",
    "\n",
    "  def _arun(self, dataframes: List[pd.DataFrame], query: str) -> Dict[str, Any]:\n",
    "      # This tool does not support async operations\n",
    "      raise NotImplementedError(\"This tool does not support async operations\")\n",
    "\n",
    "  def _process_dataframes(self, dataframes: List[pd.DataFrame], query: str) -> Dict[str, Any]:\n",
    "      try:\n",
    "          # Azure OpenAI settings\n",
    "          AZURE_OPENAI_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "          AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "          AZURE_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "\n",
    "          llm = AzureChatOpenAI(\n",
    "              openai_api_key=AZURE_OPENAI_KEY,\n",
    "              openai_api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "              azure_deployment=AZURE_DEPLOYMENT,\n",
    "              azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "              temperature=0,\n",
    "          )\n",
    "          agent = create_pandas_dataframe_agent(\n",
    "              llm,\n",
    "              dataframes,\n",
    "              agent_type=AgentType.OPENAI_FUNCTIONS,\n",
    "              verbose=True,\n",
    "              return_intermediate_steps=True,\n",
    "              number_of_head_rows=10,\n",
    "              handle_parsing_errors=True,\n",
    "              allow_dangerous_code=True\n",
    "          )\n",
    "          result = agent.invoke(\n",
    "              query,\n",
    "              include_run_info=True,\n",
    "              handle_parsing_errors=True,\n",
    "              allow_dangerous_code=True\n",
    "          )\n",
    "          \n",
    "          return result\n",
    "      except Exception as error:\n",
    "          # handle the exception\n",
    "          return {\"error\": f\"An exception occurred: {type(error).__name__} – {str(error)}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of your custom tool\n",
    "dataframe_tool = DataframeProcessingTool()\n",
    "\n",
    "r=dataframe_tool._run(selected_dataframes,final_prompt)\n",
    "display(Markdown(r['output']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure OpenAI settings\n",
    "AZURE_OPENAI_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "openai_api_key=AZURE_OPENAI_KEY,\n",
    "openai_api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "azure_deployment=AZURE_DEPLOYMENT,\n",
    "azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent, AgentType\n",
    "\n",
    "# Create an instance of your custom tool\n",
    "dataframe_tool = DataframeProcessingTool()\n",
    "\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Excel Analysis\",\n",
    "        func=dataframe_tool._run,\n",
    "        description=\"Use this tool when you need to analyze Excel data\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# agent = initialize_agent(tools, OpenAI(temperature=0), agent=\"zero-shot-react-description\", verbose=True)\n",
    "# agent.run(\"Analyze the sales data in the Excel sheets and give me a summary\")\n",
    "\n",
    "# Initialize the agent with your tool\n",
    "agent = initialize_agent(\n",
    "  tools,\n",
    "  llm,\n",
    "  agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "  verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo answer the query \"Show me Sales Performance by country,\" I need to analyze the provided dataframes and extract relevant sales performance metrics such as Actual Sales, Budget, and LE (Latest Estimate) by country. \n",
      "\n",
      "Let's proceed with the following steps:\n",
      "1. Extract and summarize the sales performance data by country.\n",
      "2. Present the results in a clear and organized manner.\n",
      "\n",
      "Action: Excel Analysis\n",
      "Action Input: {'dataframes': [dataframes], 'query': 'Show me actual sales, Budget, LE (Latest Estimate), by country'}\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\pydantic\\main.py:1087: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', category=PydanticDeprecatedSince20)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "DataframeProcessingTool._run() missing 1 required positional argument: 'query'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[89], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Use the agent\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdataframes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mselected_dataframes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Your list of dataframes\u001b[39;49;00m\n\u001b[0;32m      5\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_prompt\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m  \u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:168\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    166\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     emit_warning()\n\u001b[1;32m--> 168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\langchain\\chains\\base.py:600\u001b[0m, in \u001b[0;36mChain.run\u001b[1;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[0;32m    598\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    599\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supports only one positional argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 600\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m[\n\u001b[0;32m    601\u001b[0m         _output_key\n\u001b[0;32m    602\u001b[0m     ]\n\u001b[0;32m    604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[0;32m    605\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(kwargs, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[0;32m    606\u001b[0m         _output_key\n\u001b[0;32m    607\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:168\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    166\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     emit_warning()\n\u001b[1;32m--> 168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\langchain\\chains\\base.py:383\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \n\u001b[0;32m    353\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    376\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    377\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[0;32m    378\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m    380\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[0;32m    381\u001b[0m }\n\u001b[1;32m--> 383\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\langchain\\chains\\base.py:166\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    165\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 166\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    167\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\langchain\\chains\\base.py:156\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[0;32m    155\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 156\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    159\u001b[0m     )\n\u001b[0;32m    161\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    162\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[0;32m    163\u001b[0m     )\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\langchain\\agents\\agent.py:1612\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m   1610\u001b[0m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[0;32m   1611\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[1;32m-> 1612\u001b[0m     next_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1614\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1615\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1616\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1617\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1618\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1619\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[0;32m   1620\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return(\n\u001b[0;32m   1621\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[38;5;241m=\u001b[39mrun_manager\n\u001b[0;32m   1622\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\langchain\\agents\\agent.py:1318\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m   1309\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[0;32m   1310\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1311\u001b[0m     name_to_tool_map: Dict[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1316\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[1;32m-> 1318\u001b[0m         \u001b[43m[\u001b[49m\n\u001b[0;32m   1319\u001b[0m \u001b[43m            \u001b[49m\u001b[43ma\u001b[49m\n\u001b[0;32m   1320\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iter_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1321\u001b[0m \u001b[43m                \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1322\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m                \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1324\u001b[0m \u001b[43m                \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1326\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1327\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m   1328\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\langchain\\agents\\agent.py:1403\u001b[0m, in \u001b[0;36mAgentExecutor._iter_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m   1401\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m agent_action\n\u001b[0;32m   1402\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m agent_action \u001b[38;5;129;01min\u001b[39;00m actions:\n\u001b[1;32m-> 1403\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_perform_agent_action\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\n\u001b[0;32m   1405\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\langchain\\agents\\agent.py:1425\u001b[0m, in \u001b[0;36mAgentExecutor._perform_agent_action\u001b[1;34m(self, name_to_tool_map, color_mapping, agent_action, run_manager)\u001b[0m\n\u001b[0;32m   1423\u001b[0m         tool_run_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllm_prefix\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;66;03m# We then call the tool on the tool input to get an observation\u001b[39;00m\n\u001b[1;32m-> 1425\u001b[0m     observation \u001b[38;5;241m=\u001b[39m \u001b[43mtool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1426\u001b[0m \u001b[43m        \u001b[49m\u001b[43magent_action\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1427\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1430\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtool_run_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1431\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1433\u001b[0m     tool_run_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent\u001b[38;5;241m.\u001b[39mtool_run_logging_kwargs()\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\langchain_core\\tools.py:615\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[1;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[0m\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_to_raise:\n\u001b[0;32m    614\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_tool_error(error_to_raise)\n\u001b[1;32m--> 615\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_to_raise\n\u001b[0;32m    616\u001b[0m output \u001b[38;5;241m=\u001b[39m _format_output(content, artifact, tool_call_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, status)\n\u001b[0;32m    617\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_tool_end(output, color\u001b[38;5;241m=\u001b[39mcolor, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\langchain_core\\tools.py:584\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[1;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[0m\n\u001b[0;32m    582\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config_param \u001b[38;5;241m:=\u001b[39m _get_runnable_config_param(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run):\n\u001b[0;32m    583\u001b[0m     tool_kwargs[config_param] \u001b[38;5;241m=\u001b[39m config\n\u001b[1;32m--> 584\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtool_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtool_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    585\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse_format \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent_and_artifact\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(response) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\langchain_core\\tools.py:807\u001b[0m, in \u001b[0;36mTool._run\u001b[1;34m(self, config, run_manager, *args, **kwargs)\u001b[0m\n\u001b[0;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m config_param \u001b[38;5;241m:=\u001b[39m _get_runnable_config_param(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc):\n\u001b[0;32m    806\u001b[0m         kwargs[config_param] \u001b[38;5;241m=\u001b[39m config\n\u001b[1;32m--> 807\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTool does not support sync invocation.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: DataframeProcessingTool._run() missing 1 required positional argument: 'query'"
     ]
    }
   ],
   "source": [
    "# Use the agent\n",
    "result = agent.run({\n",
    "  \"input\": {\n",
    "      \"dataframes\": selected_dataframes,  # Your list of dataframes\n",
    "      \"query\": final_prompt\n",
    "  }\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.tools import Tool\n",
    "# from langchain.agents import create_pandas_dataframe_agent, AgentType\n",
    "# from langchain.llms import AzureChatOpenAI\n",
    "# import os\n",
    "# import pandas as pd\n",
    "# from typing import List\n",
    "\n",
    "class DataFrameProcessingTool(Tool):\n",
    "  def __init__(self):\n",
    "      super().__init__(\n",
    "          name=\"DataFrameProcessingTool\",\n",
    "          description=\"A tool to process dataframes using Azure OpenAI and a query.\"\n",
    "      )\n",
    "\n",
    "  def _run(self, dataframes: List[pd.DataFrame], query: str):\n",
    "      try:\n",
    "          # Azure OpenAI settings\n",
    "          AZURE_OPENAI_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "          AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "          AZURE_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "\n",
    "          llm = AzureChatOpenAI(\n",
    "              openai_api_key=AZURE_OPENAI_KEY,\n",
    "              openai_api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "              azure_deployment=AZURE_DEPLOYMENT,\n",
    "              azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "              temperature=0,\n",
    "          )\n",
    "          agent = create_pandas_dataframe_agent(\n",
    "              llm,\n",
    "              dataframes,\n",
    "              agent_type=AgentType.OPENAI_FUNCTIONS,\n",
    "              verbose=True,\n",
    "              return_intermediate_steps=True,\n",
    "              number_of_head_rows=10,\n",
    "              handle_parsing_errors=True,\n",
    "              allow_dangerous_code=True\n",
    "          )\n",
    "          result = agent.invoke(\n",
    "              query,\n",
    "              include_run_info=True,\n",
    "              handle_parsing_errors=True,\n",
    "              allow_dangerous_code=True\n",
    "          )\n",
    "          return result\n",
    "      except Exception as error:\n",
    "          # handle the exception\n",
    "          return f\"An exception occurred: {type(error).__name__} – {error}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualInput(BaseModel):\n",
    "    a: str = Field(description=\"first input\")\n",
    "    # b: int = Field(description=\"second number\")\n",
    "\n",
    "\n",
    "def Visual_plot(a: str) -> str:\n",
    "    \"\"\"Print Visualization\"\"\"\n",
    "    return \"VIsualization\"\n",
    "\n",
    "\n",
    "viz = StructuredTool.from_function(\n",
    "    func=Visual_plot,\n",
    "    name=\"Visualizer\",\n",
    "    description=\"Perform Visualization on the data\",\n",
    "    args_schema=VisualInput,\n",
    "    return_direct=True,\n",
    "   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'VIsualization'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viz.name\n",
    "res=viz.run(\"Print Visualization\")\n",
    "res\n",
    "viz.invoke(\"Print Visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "import os\n",
    "\n",
    "from langchain_openai import OpenAI\n",
    "# Import things that are needed generically\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain.tools import BaseTool, StructuredTool, tool\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "from pydantic.config import ConfigDict\n",
    "\n",
    "class ExcelLLMAgentInput(BaseModel):\n",
    "  df_list: List[pd.DataFrame] = Field(..., description=\"List of pandas DataFrames containing the data to query\")\n",
    "  query: str = Field(..., description=\"The user's query to be answered based on the data\")\n",
    "  api_key: str = Field(..., description=\"OpenAI API key for authentication\")\n",
    "\n",
    "  class Config:\n",
    "      arbitrary_types_allowed = True\n",
    "\n",
    "# class ExcelLLMAgentOutput(BaseModel):\n",
    "    # result: dict = Field(..., description=\"The result of the agent's query, including intermediate steps\")\n",
    "\n",
    "def excel_llm_agent(input_data: ExcelLLMAgentInput):\n",
    "    \"Helps in finding answers for the user query from the data\"\n",
    "\n",
    "    os.environ['OPENAI_API_KEY'] = input_data.api_key\n",
    "    try:\n",
    "        agent = create_pandas_dataframe_agent(\n",
    "            ChatOpenAI(temperature=0, model=\"gpt-4\"),\n",
    "            input_data.df_list,\n",
    "            agent_type=AgentType.OPENAI_FUNCTIONS,\n",
    "            verbose=True,\n",
    "            return_intermediate_steps=True,\n",
    "            number_of_head_rows=5,\n",
    "            handle_parsing_errors=True,\n",
    "            allow_dangerous_code=True\n",
    "        )\n",
    "        result = agent.invoke(\n",
    "            input_data.query,\n",
    "            include_run_info=True,\n",
    "            handle_parsing_errors=True,\n",
    "            allow_dangerous_code=True\n",
    "        )\n",
    "        # return ExcelLLMAgentOutput(result=result)\n",
    "        return result\n",
    "\n",
    "    except Exception as error:\n",
    "        # handle the exception\n",
    "        error_message = f\"An exception occurred: {type(error).__name__} – {str(error)}\"\n",
    "        st.write(error_message)\n",
    "        # return ExcelLLMAgentOutput(result={\"error\": error_message})\n",
    "        return {\"error\": error_message}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def excel_llm_agent(df_list,query,api_key):\n",
    "    \"Helps in findng answer for the user query from the data\"\n",
    "\n",
    "    # os.environ['OPENAI_API_KEY'] = api_key\n",
    "    # try:\n",
    "    #     agent = create_pandas_dataframe_agent(ChatOpenAI(temperature=0, model=\"gpt-4\"),\n",
    "    #                                           df_list,agent_type=AgentType.OPENAI_FUNCTIONS,\n",
    "    #                                             verbose=True,return_intermediate_steps = True,\n",
    "    #                                               number_of_head_rows = 10,\n",
    "    #                                                 handle_parsing_errors=True,\n",
    "    #                                                 allow_dangerous_code=True)\n",
    "    #     result = agent.invoke(query,include_run_info = True,handle_parsing_errors=True,allow_dangerous_code=True)\n",
    "    #     return result\n",
    "    # except Exception as error:\n",
    "    #     # handle the exception\n",
    "    #     st.write(\"An exception occurred:\", type(error).__name__, \"–\", error)\n",
    "\n",
    "    return \"Data analysi\"\n",
    "\n",
    "Data_query = StructuredTool.from_function(\n",
    "    func=excel_llm_agent,\n",
    "    name=\"Excel LLM Agent\",\n",
    "    description=\"Use this tool when you need to analyze or query data from Excel files or pandas DataFrames.\",\n",
    "    args_schema=ExcelLLMAgentInput,\n",
    "    return_direct=True,\n",
    "   \n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "PydanticInvalidForJsonSchema",
     "evalue": "Cannot generate a JsonSchema for core_schema.IsInstanceSchema (<class 'pandas.core.frame.DataFrame'>)\n\nFor further information visit https://errors.pydantic.dev/2.8/u/invalid-for-json-schema",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPydanticInvalidForJsonSchema\u001b[0m              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[81], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mData_query\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\langchain_core\\tools.py:914\u001b[0m, in \u001b[0;36mStructuredTool.args\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    911\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    912\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21margs\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[0;32m    913\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"The tool's input arguments.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs_schema\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproperties\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\pydantic\\main.py:1331\u001b[0m, in \u001b[0;36mBaseModel.schema\u001b[1;34m(cls, by_alias, ref_template)\u001b[0m\n\u001b[0;32m   1323\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m   1324\u001b[0m \u001b[38;5;129m@typing_extensions\u001b[39m\u001b[38;5;241m.\u001b[39mdeprecated(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe `schema` method is deprecated; use `model_json_schema` instead.\u001b[39m\u001b[38;5;124m'\u001b[39m, category\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mschema\u001b[39m(  \u001b[38;5;66;03m# noqa: D102\u001b[39;00m\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28mcls\u001b[39m, by_alias: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, ref_template: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m DEFAULT_REF_TEMPLATE\n\u001b[0;32m   1327\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:  \u001b[38;5;66;03m# noqa UP006\u001b[39;00m\n\u001b[0;32m   1328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1329\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe `schema` method is deprecated; use `model_json_schema` instead.\u001b[39m\u001b[38;5;124m'\u001b[39m, category\u001b[38;5;241m=\u001b[39mPydanticDeprecatedSince20\n\u001b[0;32m   1330\u001b[0m     )\n\u001b[1;32m-> 1331\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_json_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mby_alias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_alias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref_template\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mref_template\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\pydantic\\main.py:450\u001b[0m, in \u001b[0;36mBaseModel.model_json_schema\u001b[1;34m(cls, by_alias, ref_template, schema_generator, mode)\u001b[0m\n\u001b[0;32m    430\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmodel_json_schema\u001b[39m(\n\u001b[0;32m    432\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    436\u001b[0m     mode: JsonSchemaMode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    437\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[0;32m    438\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generates a JSON schema for a model class.\u001b[39;00m\n\u001b[0;32m    439\u001b[0m \n\u001b[0;32m    440\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;124;03m        The JSON schema for the given model class.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 450\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_json_schema\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mby_alias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_alias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref_template\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mref_template\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema_generator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\pydantic\\json_schema.py:2264\u001b[0m, in \u001b[0;36mmodel_json_schema\u001b[1;34m(cls, by_alias, ref_template, schema_generator, mode)\u001b[0m\n\u001b[0;32m   2261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_json_schema() must be called on a subclass of BaseModel, not BaseModel itself.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   2263\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__pydantic_core_schema__, _mock_val_ser\u001b[38;5;241m.\u001b[39mMockCoreSchema), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthis is a bug! please report it\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m-> 2264\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mschema_generator_instance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_core_schema__\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\pydantic\\json_schema.py:414\u001b[0m, in \u001b[0;36mGenerateJsonSchema.generate\u001b[1;34m(self, schema, mode)\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_used:\n\u001b[0;32m    408\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PydanticUserError(\n\u001b[0;32m    409\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis JSON schema generator has already been used to generate a JSON schema. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    410\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYou must create a new instance of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to generate a new JSON schema.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    411\u001b[0m         code\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjson-schema-already-used\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    412\u001b[0m     )\n\u001b[1;32m--> 414\u001b[0m json_schema: JsonSchemaValue \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    415\u001b[0m json_ref_counts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_json_ref_counts(json_schema)\n\u001b[0;32m    417\u001b[0m \u001b[38;5;66;03m# Remove the top-level $ref if present; note that the _generate method already ensures there are no sibling keys\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\pydantic\\json_schema.py:553\u001b[0m, in \u001b[0;36mGenerateJsonSchema.generate_inner\u001b[1;34m(self, schema)\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m json_schema\n\u001b[0;32m    551\u001b[0m     current_handler \u001b[38;5;241m=\u001b[39m _schema_generation_shared\u001b[38;5;241m.\u001b[39mGenerateJsonSchemaHandler(\u001b[38;5;28mself\u001b[39m, new_handler_func)\n\u001b[1;32m--> 553\u001b[0m json_schema \u001b[38;5;241m=\u001b[39m \u001b[43mcurrent_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    554\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _core_utils\u001b[38;5;241m.\u001b[39mis_core_schema(schema):\n\u001b[0;32m    555\u001b[0m     json_schema \u001b[38;5;241m=\u001b[39m populate_defs(schema, json_schema)\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\pydantic\\_internal\\_schema_generation_shared.py:37\u001b[0m, in \u001b[0;36mGenerateJsonSchemaHandler.__call__\u001b[1;34m(self, core_schema)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, core_schema: CoreSchemaOrField, \u001b[38;5;241m/\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m JsonSchemaValue:\n\u001b[1;32m---> 37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcore_schema\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\pydantic\\json_schema.py:527\u001b[0m, in \u001b[0;36mGenerateJsonSchema.generate_inner.<locals>.new_handler_func\u001b[1;34m(schema_or_field, current_handler, js_modify_function)\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnew_handler_func\u001b[39m(\n\u001b[0;32m    523\u001b[0m     schema_or_field: CoreSchemaOrField,\n\u001b[0;32m    524\u001b[0m     current_handler: GetJsonSchemaHandler \u001b[38;5;241m=\u001b[39m current_handler,\n\u001b[0;32m    525\u001b[0m     js_modify_function: GetJsonSchemaFunction \u001b[38;5;241m=\u001b[39m js_modify_function,\n\u001b[0;32m    526\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m JsonSchemaValue:\n\u001b[1;32m--> 527\u001b[0m     json_schema \u001b[38;5;241m=\u001b[39m \u001b[43mjs_modify_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema_or_field\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_handler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    528\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _core_utils\u001b[38;5;241m.\u001b[39mis_core_schema(schema_or_field):\n\u001b[0;32m    529\u001b[0m         json_schema \u001b[38;5;241m=\u001b[39m populate_defs(schema_or_field, json_schema)\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\pydantic\\main.py:669\u001b[0m, in \u001b[0;36mBaseModel.__get_pydantic_json_schema__\u001b[1;34m(cls, core_schema, handler)\u001b[0m\n\u001b[0;32m    645\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    646\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__get_pydantic_json_schema__\u001b[39m(\n\u001b[0;32m    647\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    650\u001b[0m     \u001b[38;5;241m/\u001b[39m,\n\u001b[0;32m    651\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m JsonSchemaValue:\n\u001b[0;32m    652\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Hook into generating the model's JSON schema.\u001b[39;00m\n\u001b[0;32m    653\u001b[0m \n\u001b[0;32m    654\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    667\u001b[0m \u001b[38;5;124;03m        A JSON schema, as a Python object.\u001b[39;00m\n\u001b[0;32m    668\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 669\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcore_schema\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\pydantic\\_internal\\_schema_generation_shared.py:37\u001b[0m, in \u001b[0;36mGenerateJsonSchemaHandler.__call__\u001b[1;34m(self, core_schema)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, core_schema: CoreSchemaOrField, \u001b[38;5;241m/\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m JsonSchemaValue:\n\u001b[1;32m---> 37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcore_schema\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\pydantic\\json_schema.py:527\u001b[0m, in \u001b[0;36mGenerateJsonSchema.generate_inner.<locals>.new_handler_func\u001b[1;34m(schema_or_field, current_handler, js_modify_function)\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnew_handler_func\u001b[39m(\n\u001b[0;32m    523\u001b[0m     schema_or_field: CoreSchemaOrField,\n\u001b[0;32m    524\u001b[0m     current_handler: GetJsonSchemaHandler \u001b[38;5;241m=\u001b[39m current_handler,\n\u001b[0;32m    525\u001b[0m     js_modify_function: GetJsonSchemaFunction \u001b[38;5;241m=\u001b[39m js_modify_function,\n\u001b[0;32m    526\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m JsonSchemaValue:\n\u001b[1;32m--> 527\u001b[0m     json_schema \u001b[38;5;241m=\u001b[39m \u001b[43mjs_modify_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema_or_field\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_handler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    528\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _core_utils\u001b[38;5;241m.\u001b[39mis_core_schema(schema_or_field):\n\u001b[0;32m    529\u001b[0m         json_schema \u001b[38;5;241m=\u001b[39m populate_defs(schema_or_field, json_schema)\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:228\u001b[0m, in \u001b[0;36mmodify_model_json_schema\u001b[1;34m(schema_or_field, handler, cls, title)\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mroot_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RootModel\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dataclasses\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_builtin_dataclass\n\u001b[1;32m--> 228\u001b[0m json_schema \u001b[38;5;241m=\u001b[39m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema_or_field\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    229\u001b[0m original_schema \u001b[38;5;241m=\u001b[39m handler\u001b[38;5;241m.\u001b[39mresolve_ref_schema(json_schema)\n\u001b[0;32m    230\u001b[0m \u001b[38;5;66;03m# Preserve the fact that definitions schemas should never have sibling keys:\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\pydantic\\_internal\\_schema_generation_shared.py:37\u001b[0m, in \u001b[0;36mGenerateJsonSchemaHandler.__call__\u001b[1;34m(self, core_schema)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, core_schema: CoreSchemaOrField, \u001b[38;5;241m/\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m JsonSchemaValue:\n\u001b[1;32m---> 37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcore_schema\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\pydantic\\json_schema.py:510\u001b[0m, in \u001b[0;36mGenerateJsonSchema.generate_inner.<locals>.handler_func\u001b[1;34m(schema_or_field)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _core_utils\u001b[38;5;241m.\u001b[39mis_core_schema(schema_or_field) \u001b[38;5;129;01mor\u001b[39;00m _core_utils\u001b[38;5;241m.\u001b[39mis_core_schema_field(schema_or_field):\n\u001b[0;32m    509\u001b[0m     generate_for_schema_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_schema_type_to_method[schema_or_field[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m--> 510\u001b[0m     json_schema \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_for_schema_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema_or_field\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnexpected schema type: schema=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mschema_or_field\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\pydantic\\json_schema.py:1410\u001b[0m, in \u001b[0;36mGenerateJsonSchema.model_schema\u001b[1;34m(self, schema)\u001b[0m\n\u001b[0;32m   1407\u001b[0m title \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1409\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config_wrapper_stack\u001b[38;5;241m.\u001b[39mpush(config):\n\u001b[1;32m-> 1410\u001b[0m     json_schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mschema\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1412\u001b[0m json_schema_extra \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjson_schema_extra\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1413\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__pydantic_root_model__:\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\pydantic\\json_schema.py:553\u001b[0m, in \u001b[0;36mGenerateJsonSchema.generate_inner\u001b[1;34m(self, schema)\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m json_schema\n\u001b[0;32m    551\u001b[0m     current_handler \u001b[38;5;241m=\u001b[39m _schema_generation_shared\u001b[38;5;241m.\u001b[39mGenerateJsonSchemaHandler(\u001b[38;5;28mself\u001b[39m, new_handler_func)\n\u001b[1;32m--> 553\u001b[0m json_schema \u001b[38;5;241m=\u001b[39m \u001b[43mcurrent_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    554\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _core_utils\u001b[38;5;241m.\u001b[39mis_core_schema(schema):\n\u001b[0;32m    555\u001b[0m     json_schema \u001b[38;5;241m=\u001b[39m populate_defs(schema, json_schema)\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\pydantic\\_internal\\_schema_generation_shared.py:37\u001b[0m, in \u001b[0;36mGenerateJsonSchemaHandler.__call__\u001b[1;34m(self, core_schema)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, core_schema: CoreSchemaOrField, \u001b[38;5;241m/\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m JsonSchemaValue:\n\u001b[1;32m---> 37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcore_schema\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\pydantic\\json_schema.py:510\u001b[0m, in \u001b[0;36mGenerateJsonSchema.generate_inner.<locals>.handler_func\u001b[1;34m(schema_or_field)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _core_utils\u001b[38;5;241m.\u001b[39mis_core_schema(schema_or_field) \u001b[38;5;129;01mor\u001b[39;00m _core_utils\u001b[38;5;241m.\u001b[39mis_core_schema_field(schema_or_field):\n\u001b[0;32m    509\u001b[0m     generate_for_schema_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_schema_type_to_method[schema_or_field[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m--> 510\u001b[0m     json_schema \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_for_schema_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema_or_field\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnexpected schema type: schema=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mschema_or_field\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\pydantic\\json_schema.py:1505\u001b[0m, in \u001b[0;36mGenerateJsonSchema.model_fields_schema\u001b[1;34m(self, schema)\u001b[0m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mserialization\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m   1504\u001b[0m     named_required_fields\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name_required_computed_fields(schema\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomputed_fields\u001b[39m\u001b[38;5;124m'\u001b[39m, [])))\n\u001b[1;32m-> 1505\u001b[0m json_schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_named_required_fields_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnamed_required_fields\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1506\u001b[0m extras_schema \u001b[38;5;241m=\u001b[39m schema\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mextras_schema\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extras_schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\pydantic\\json_schema.py:1313\u001b[0m, in \u001b[0;36mGenerateJsonSchema._named_required_fields_schema\u001b[1;34m(self, named_required_fields)\u001b[0m\n\u001b[0;32m   1311\u001b[0m     name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_alias_name(field, name)\n\u001b[0;32m   1312\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1313\u001b[0m     field_json_schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfield\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m   1314\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m PydanticOmit:\n\u001b[0;32m   1315\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\pydantic\\json_schema.py:553\u001b[0m, in \u001b[0;36mGenerateJsonSchema.generate_inner\u001b[1;34m(self, schema)\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m json_schema\n\u001b[0;32m    551\u001b[0m     current_handler \u001b[38;5;241m=\u001b[39m _schema_generation_shared\u001b[38;5;241m.\u001b[39mGenerateJsonSchemaHandler(\u001b[38;5;28mself\u001b[39m, new_handler_func)\n\u001b[1;32m--> 553\u001b[0m json_schema \u001b[38;5;241m=\u001b[39m \u001b[43mcurrent_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    554\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _core_utils\u001b[38;5;241m.\u001b[39mis_core_schema(schema):\n\u001b[0;32m    555\u001b[0m     json_schema \u001b[38;5;241m=\u001b[39m populate_defs(schema, json_schema)\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\pydantic\\_internal\\_schema_generation_shared.py:37\u001b[0m, in \u001b[0;36mGenerateJsonSchemaHandler.__call__\u001b[1;34m(self, core_schema)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, core_schema: CoreSchemaOrField, \u001b[38;5;241m/\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m JsonSchemaValue:\n\u001b[1;32m---> 37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcore_schema\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\pydantic\\json_schema.py:545\u001b[0m, in \u001b[0;36mGenerateJsonSchema.generate_inner.<locals>.new_handler_func\u001b[1;34m(schema_or_field, current_handler, js_modify_function)\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnew_handler_func\u001b[39m(\n\u001b[0;32m    541\u001b[0m     schema_or_field: CoreSchemaOrField,\n\u001b[0;32m    542\u001b[0m     current_handler: GetJsonSchemaHandler \u001b[38;5;241m=\u001b[39m current_handler,\n\u001b[0;32m    543\u001b[0m     js_modify_function: GetJsonSchemaFunction \u001b[38;5;241m=\u001b[39m js_modify_function,\n\u001b[0;32m    544\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m JsonSchemaValue:\n\u001b[1;32m--> 545\u001b[0m     json_schema \u001b[38;5;241m=\u001b[39m \u001b[43mjs_modify_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema_or_field\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_handler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    546\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _core_utils\u001b[38;5;241m.\u001b[39mis_core_schema(schema_or_field):\n\u001b[0;32m    547\u001b[0m         json_schema \u001b[38;5;241m=\u001b[39m populate_defs(schema_or_field, json_schema)\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:2249\u001b[0m, in \u001b[0;36mget_json_schema_update_func.<locals>.json_schema_update_func\u001b[1;34m(core_schema_or_field, handler)\u001b[0m\n\u001b[0;32m   2246\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mjson_schema_update_func\u001b[39m(\n\u001b[0;32m   2247\u001b[0m     core_schema_or_field: CoreSchemaOrField, handler: GetJsonSchemaHandler\n\u001b[0;32m   2248\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m JsonSchemaValue:\n\u001b[1;32m-> 2249\u001b[0m     json_schema \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcore_schema_or_field\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mjson_schema_update}\n\u001b[0;32m   2250\u001b[0m     add_json_schema_extra(json_schema, json_schema_extra)\n\u001b[0;32m   2251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m json_schema\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\pydantic\\_internal\\_schema_generation_shared.py:37\u001b[0m, in \u001b[0;36mGenerateJsonSchemaHandler.__call__\u001b[1;34m(self, core_schema)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, core_schema: CoreSchemaOrField, \u001b[38;5;241m/\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m JsonSchemaValue:\n\u001b[1;32m---> 37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcore_schema\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\pydantic\\json_schema.py:510\u001b[0m, in \u001b[0;36mGenerateJsonSchema.generate_inner.<locals>.handler_func\u001b[1;34m(schema_or_field)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _core_utils\u001b[38;5;241m.\u001b[39mis_core_schema(schema_or_field) \u001b[38;5;129;01mor\u001b[39;00m _core_utils\u001b[38;5;241m.\u001b[39mis_core_schema_field(schema_or_field):\n\u001b[0;32m    509\u001b[0m     generate_for_schema_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_schema_type_to_method[schema_or_field[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m--> 510\u001b[0m     json_schema \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_for_schema_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema_or_field\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnexpected schema type: schema=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mschema_or_field\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\pydantic\\json_schema.py:1381\u001b[0m, in \u001b[0;36mGenerateJsonSchema.model_field_schema\u001b[1;34m(self, schema)\u001b[0m\n\u001b[0;32m   1372\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmodel_field_schema\u001b[39m(\u001b[38;5;28mself\u001b[39m, schema: core_schema\u001b[38;5;241m.\u001b[39mModelField) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m JsonSchemaValue:\n\u001b[0;32m   1373\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generates a JSON schema that matches a schema that defines a model field.\u001b[39;00m\n\u001b[0;32m   1374\u001b[0m \n\u001b[0;32m   1375\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1379\u001b[0m \u001b[38;5;124;03m        The generated JSON schema.\u001b[39;00m\n\u001b[0;32m   1380\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1381\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mschema\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\pydantic\\json_schema.py:553\u001b[0m, in \u001b[0;36mGenerateJsonSchema.generate_inner\u001b[1;34m(self, schema)\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m json_schema\n\u001b[0;32m    551\u001b[0m     current_handler \u001b[38;5;241m=\u001b[39m _schema_generation_shared\u001b[38;5;241m.\u001b[39mGenerateJsonSchemaHandler(\u001b[38;5;28mself\u001b[39m, new_handler_func)\n\u001b[1;32m--> 553\u001b[0m json_schema \u001b[38;5;241m=\u001b[39m \u001b[43mcurrent_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    554\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _core_utils\u001b[38;5;241m.\u001b[39mis_core_schema(schema):\n\u001b[0;32m    555\u001b[0m     json_schema \u001b[38;5;241m=\u001b[39m populate_defs(schema, json_schema)\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\pydantic\\_internal\\_schema_generation_shared.py:37\u001b[0m, in \u001b[0;36mGenerateJsonSchemaHandler.__call__\u001b[1;34m(self, core_schema)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, core_schema: CoreSchemaOrField, \u001b[38;5;241m/\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m JsonSchemaValue:\n\u001b[1;32m---> 37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcore_schema\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\pydantic\\json_schema.py:510\u001b[0m, in \u001b[0;36mGenerateJsonSchema.generate_inner.<locals>.handler_func\u001b[1;34m(schema_or_field)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _core_utils\u001b[38;5;241m.\u001b[39mis_core_schema(schema_or_field) \u001b[38;5;129;01mor\u001b[39;00m _core_utils\u001b[38;5;241m.\u001b[39mis_core_schema_field(schema_or_field):\n\u001b[0;32m    509\u001b[0m     generate_for_schema_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_schema_type_to_method[schema_or_field[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m--> 510\u001b[0m     json_schema \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_for_schema_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema_or_field\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnexpected schema type: schema=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mschema_or_field\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\pydantic\\json_schema.py:850\u001b[0m, in \u001b[0;36mGenerateJsonSchema.list_schema\u001b[1;34m(self, schema)\u001b[0m\n\u001b[0;32m    841\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlist_schema\u001b[39m(\u001b[38;5;28mself\u001b[39m, schema: core_schema\u001b[38;5;241m.\u001b[39mListSchema) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m JsonSchemaValue:\n\u001b[0;32m    842\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a schema that matches a list schema.\u001b[39;00m\n\u001b[0;32m    843\u001b[0m \n\u001b[0;32m    844\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    848\u001b[0m \u001b[38;5;124;03m        The generated JSON schema.\u001b[39;00m\n\u001b[0;32m    849\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 850\u001b[0m     items_schema \u001b[38;5;241m=\u001b[39m {} \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitems_schema\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m schema \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mitems_schema\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    851\u001b[0m     json_schema \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitems\u001b[39m\u001b[38;5;124m'\u001b[39m: items_schema}\n\u001b[0;32m    852\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_with_validations(json_schema, schema, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mValidationsMapping\u001b[38;5;241m.\u001b[39marray)\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\pydantic\\json_schema.py:553\u001b[0m, in \u001b[0;36mGenerateJsonSchema.generate_inner\u001b[1;34m(self, schema)\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m json_schema\n\u001b[0;32m    551\u001b[0m     current_handler \u001b[38;5;241m=\u001b[39m _schema_generation_shared\u001b[38;5;241m.\u001b[39mGenerateJsonSchemaHandler(\u001b[38;5;28mself\u001b[39m, new_handler_func)\n\u001b[1;32m--> 553\u001b[0m json_schema \u001b[38;5;241m=\u001b[39m \u001b[43mcurrent_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    554\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _core_utils\u001b[38;5;241m.\u001b[39mis_core_schema(schema):\n\u001b[0;32m    555\u001b[0m     json_schema \u001b[38;5;241m=\u001b[39m populate_defs(schema, json_schema)\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\pydantic\\_internal\\_schema_generation_shared.py:37\u001b[0m, in \u001b[0;36mGenerateJsonSchemaHandler.__call__\u001b[1;34m(self, core_schema)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, core_schema: CoreSchemaOrField, \u001b[38;5;241m/\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m JsonSchemaValue:\n\u001b[1;32m---> 37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcore_schema\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\pydantic\\json_schema.py:510\u001b[0m, in \u001b[0;36mGenerateJsonSchema.generate_inner.<locals>.handler_func\u001b[1;34m(schema_or_field)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _core_utils\u001b[38;5;241m.\u001b[39mis_core_schema(schema_or_field) \u001b[38;5;129;01mor\u001b[39;00m _core_utils\u001b[38;5;241m.\u001b[39mis_core_schema_field(schema_or_field):\n\u001b[0;32m    509\u001b[0m     generate_for_schema_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_schema_type_to_method[schema_or_field[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m--> 510\u001b[0m     json_schema \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_for_schema_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema_or_field\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnexpected schema type: schema=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mschema_or_field\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\pydantic\\json_schema.py:812\u001b[0m, in \u001b[0;36mGenerateJsonSchema.is_instance_schema\u001b[1;34m(self, schema)\u001b[0m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_instance_schema\u001b[39m(\u001b[38;5;28mself\u001b[39m, schema: core_schema\u001b[38;5;241m.\u001b[39mIsInstanceSchema) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m JsonSchemaValue:\n\u001b[0;32m    802\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Handles JSON schema generation for a core schema that checks if a value is an instance of a class.\u001b[39;00m\n\u001b[0;32m    803\u001b[0m \n\u001b[0;32m    804\u001b[0m \u001b[38;5;124;03m    Unless overridden in a subclass, this raises an error.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[38;5;124;03m        The generated JSON schema.\u001b[39;00m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 812\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_invalid_for_json_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcore_schema.IsInstanceSchema (\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mschema\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\pydantic\\json_schema.py:2173\u001b[0m, in \u001b[0;36mGenerateJsonSchema.handle_invalid_for_json_schema\u001b[1;34m(self, schema, error_info)\u001b[0m\n\u001b[0;32m   2172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhandle_invalid_for_json_schema\u001b[39m(\u001b[38;5;28mself\u001b[39m, schema: CoreSchemaOrField, error_info: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m JsonSchemaValue:\n\u001b[1;32m-> 2173\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PydanticInvalidForJsonSchema(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot generate a JsonSchema for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_info\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mPydanticInvalidForJsonSchema\u001b[0m: Cannot generate a JsonSchema for core_schema.IsInstanceSchema (<class 'pandas.core.frame.DataFrame'>)\n\nFor further information visit https://errors.pydantic.dev/2.8/u/invalid-for-json-schema"
     ]
    }
   ],
   "source": [
    "Data_query.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "BaseTool.run() missing 1 required positional argument: 'tool_input'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[77], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Instantiate the input model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# input_data = ExcelLLMAgentInput(\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#     df_list=selected_dataframes,\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#     query=\"What is the sum of column1?\",\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#     api_key=\"your_openai_api_key_here\"  # Replace with your actual OpenAI API key\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[43mData_query\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mselected_dataframes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhat is the sum of column1?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43myour_openai_api_key_here\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Data_query.run(selected_dataframes,\"Hi\",\"hello\")\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: BaseTool.run() missing 1 required positional argument: 'tool_input'"
     ]
    }
   ],
   "source": [
    "# Instantiate the input model\n",
    "# input_data = ExcelLLMAgentInput(\n",
    "#     df_list=selected_dataframes,\n",
    "#     query=\"What is the sum of column1?\",\n",
    "#     api_key=\"your_openai_api_key_here\"  # Replace with your actual OpenAI API key\n",
    "# )\n",
    "Data_query.run(df_list=selected_dataframes,\n",
    "    query=\"What is the sum of column1?\",\n",
    "    api_key=\"your_openai_api_key_here\")\n",
    "# Data_query.run(selected_dataframes,\"Hi\",\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Any\n",
    "import os\n",
    "# import streamlit as st\n",
    "    # from some_module import create_pandas_dataframe_agent, ChatOpenAI, AgentType  # Replace with actual imports\n",
    "\n",
    "def dataframe_to_dict(df: pd.DataFrame) -> Dict[str, List[Any]]:\n",
    "  \"\"\"Convert a DataFrame to a dictionary.\"\"\"\n",
    "  return df.to_dict(orient='list')\n",
    "\n",
    "def dict_to_dataframe(data: Dict[str, List[Any]]) -> pd.DataFrame:\n",
    "  \"\"\"Convert a dictionary to a DataFrame.\"\"\"\n",
    "  return pd.DataFrame(data)\n",
    "\n",
    "class ExcelLLMAgentInput(BaseModel):\n",
    "  df_list: List[Dict[str, List[Any]]] = Field(..., description=\"List of pandas DataFrames containing the data to query\")\n",
    "  query: str = Field(..., description=\"The user's query to be answered based on the data\")\n",
    "  api_key: str = Field(..., description=\"OpenAI API key for authentication\")\n",
    "\n",
    "  class Config:\n",
    "      arbitrary_types_allowed = True\n",
    "\n",
    "  @classmethod\n",
    "  def from_dataframes(cls, df_list: List[pd.DataFrame], query: str, api_key: str):\n",
    "      \"\"\"Create an instance from a list of DataFrames.\"\"\"\n",
    "      df_dict_list = [dataframe_to_dict(df) for df in df_list]\n",
    "      return cls(df_list=df_dict_list, query=query, api_key=api_key)\n",
    "\n",
    "  def to_dataframes(self) -> List[pd.DataFrame]:\n",
    "      \"\"\"Convert the df_list back to a list of DataFrames.\"\"\"\n",
    "      return [dict_to_dataframe(df_dict) for df_dict in self.df_list]\n",
    "\n",
    "class ExcelLLMAgentOutput(BaseModel):\n",
    "  result: Dict = Field(..., description=\"The result of the agent's query, including intermediate steps\")\n",
    "\n",
    "def excel_llm_agent(input_data: ExcelLLMAgentInput) -> ExcelLLMAgentOutput:\n",
    "#   \"\"\"Helps in finding answers for the user query from the data.\"\"\"\n",
    "  \n",
    "#   os.environ['OPENAI_API_KEY'] = input_data.api_key\n",
    "#   try:\n",
    "#       df_list = input_data.to_dataframes()\n",
    "#       agent = create_pandas_dataframe_agent(\n",
    "#           ChatOpenAI(temperature=0, model=\"gpt-4\"),\n",
    "#           df_list,\n",
    "#           agent_type=AgentType.OPENAI_FUNCTIONS,\n",
    "#           verbose=True,\n",
    "#           return_intermediate_steps=True,\n",
    "#           number_of_head_rows=5,\n",
    "#           handle_parsing_errors=True,\n",
    "#           allow_dangerous_code=True\n",
    "#       )\n",
    "#       result = agent.invoke(\n",
    "#           input_data.query,\n",
    "#           include_run_info=True,\n",
    "#           handle_parsing_errors=True,\n",
    "#           allow_dangerous_code=True\n",
    "#       )\n",
    "#       return ExcelLLMAgentOutput(result=result)\n",
    "    return \"Called Excel agent\"\n",
    "#   except Exception as error:\n",
    "#       # Handle the exception\n",
    "#       error_message = f\"An exception occurred: {type(error).__name__} – {str(error)}\"\n",
    "#       st.write(error_message)\n",
    "#       return ExcelLLMAgentOutput(result={\"error\": error_message})\n",
    "  \n",
    "\n",
    "\n",
    "Data_query = StructuredTool.from_function(\n",
    "    func=excel_llm_agent,\n",
    "    name=\"Excel LLM Agent\",\n",
    "    description=\"Use this tool when you need to analyze or query data from Excel files or pandas DataFrames.\",\n",
    "    args_schema=ExcelLLMAgentInput,\n",
    "    return_direct=True,\n",
    "   \n",
    ")\n",
    "\n",
    "# Instantiate the input model\n",
    "input_data = ExcelLLMAgentInput.from_dataframes(\n",
    "    # df_list=[df1, df2],\n",
    "    df_list=selected_dataframes,\n",
    "    query=\"What is the sum of column1?\",\n",
    "    api_key=\"your_openai_api_key_here\"  # Replace with your actual OpenAI API key\n",
    ")\n",
    "\n",
    "# Test the function\n",
    "if __name__ == \"__main__\":\n",
    "  # Create sample DataFrames\n",
    "  data1 = {\n",
    "      'column1': [1, 2, 3],\n",
    "      'column2': ['a', 'b', 'c']\n",
    "  }\n",
    "  data2 = {\n",
    "      'column1': [4, 5, 6],\n",
    "      'column2': ['d', 'e', 'f']\n",
    "  }\n",
    "  df1 = pd.DataFrame(data1)\n",
    "  df2 = pd.DataFrame(data2)\n",
    "\n",
    "  # Instantiate the input model\n",
    "  input_data = ExcelLLMAgentInput.from_dataframes(\n",
    "      # df_list=[df1, df2],\n",
    "      df_list=selected_dataframes,\n",
    "      query=\"What is the sum of column1?\",\n",
    "      api_key=\"your_openai_api_key_here\"  # Replace with your actual OpenAI API key\n",
    "  )\n",
    "\n",
    "  # Call the function\n",
    "  output = excel_llm_agent(input_data)\n",
    "  print(output)\n",
    "\n",
    "Data_query.run(input_data=input_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'df_list': {'description': 'List of pandas DataFrames containing the data to query',\n",
       "  'items': {'additionalProperties': {'items': {}, 'type': 'array'},\n",
       "   'type': 'object'},\n",
       "  'title': 'Df List',\n",
       "  'type': 'array'},\n",
       " 'query': {'description': \"The user's query to be answered based on the data\",\n",
       "  'title': 'Query',\n",
       "  'type': 'string'},\n",
       " 'api_key': {'description': 'OpenAI API key for authentication',\n",
       "  'title': 'Api Key',\n",
       "  'type': 'string'}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_query.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Called Excel agent\n"
     ]
    }
   ],
   "source": [
    "# Test the function\n",
    "if __name__ == \"__main__\":\n",
    "  # Create sample DataFrames\n",
    "  data1 = {\n",
    "      'column1': [1, 2, 3],\n",
    "      'column2': ['a', 'b', 'c']\n",
    "  }\n",
    "  data2 = {\n",
    "      'column1': [4, 5, 6],\n",
    "      'column2': ['d', 'e', 'f']\n",
    "  }\n",
    "  df1 = pd.DataFrame(data1)\n",
    "  df2 = pd.DataFrame(data2)\n",
    "\n",
    "  # Instantiate the input model\n",
    "  input_data = ExcelLLMAgentInput.from_dataframes(\n",
    "      # df_list=[df1, df2],\n",
    "      df_list=selected_dataframes,\n",
    "      query=\"What is the sum of column1?\",\n",
    "      api_key=\"your_openai_api_key_here\"  # Replace with your actual OpenAI API key\n",
    "  )\n",
    "\n",
    "  # Call the function\n",
    "  output = excel_llm_agent(input_data)\n",
    "  print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_list=[   column1 column2\n",
      "0        1       a\n",
      "1        2       b\n",
      "2        3       c,    column1 column2\n",
      "0        4       d\n",
      "1        5       e\n",
      "2        6       f] query='What is the sum of column1?'\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field, ConfigDict\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "\n",
    "class ExcelLLMAgentInput(BaseModel):\n",
    "  df_list: List[pd.DataFrame] = Field(..., description=\"List of pandas DataFrames containing the data to query\")\n",
    "  query: str = Field(..., description=\"The user's query to be answered based on the data\")\n",
    "\n",
    "  class Config:\n",
    "      arbitrary_types_allowed = True\n",
    "\n",
    "# Example usage\n",
    "data1 = {\n",
    "  'column1': [1, 2, 3],\n",
    "  'column2': ['a', 'b', 'c']\n",
    "}\n",
    "data2 = {\n",
    "  'column1': [4, 5, 6],\n",
    "  'column2': ['d', 'e', 'f']\n",
    "}\n",
    "df1 = pd.DataFrame(data1)\n",
    "df2 = pd.DataFrame(data2)\n",
    "dataframes=[]\n",
    "dataframes.append(df1)\n",
    "dataframes.append(df2)\n",
    "\n",
    "\n",
    "model = ExcelLLMAgentInput(df_list=dataframes, query=\"What is the sum of column1?\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(selected_dataframes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_openai import AzureOpenAI\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "AZURE_OPENAI_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "\n",
    "llm = AzureOpenAI(\n",
    "openai_api_key=AZURE_OPENAI_KEY,\n",
    "openai_api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "azure_deployment=AZURE_DEPLOYMENT,\n",
    "azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The completion operation does not work with the specified model, gpt-4o. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhich GPT model am I using ?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DataWhisper\\Datawhisper_venv\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:385\u001b[0m, in \u001b[0;36mBaseLLM.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    376\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    377\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    381\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    382\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    383\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    384\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m--> 385\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    389\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    394\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    395\u001b[0m         \u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    396\u001b[0m         \u001b[38;5;241m.\u001b[39mtext\n\u001b[0;32m    397\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DataWhisper\\Datawhisper_venv\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:750\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    743\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    744\u001b[0m     prompts: List[PromptValue],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    747\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    748\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    749\u001b[0m     prompt_strings \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_strings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DataWhisper\\Datawhisper_venv\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:944\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[1;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    929\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    930\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    931\u001b[0m         callback_manager\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[0;32m    932\u001b[0m             dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    942\u001b[0m         )\n\u001b[0;32m    943\u001b[0m     ]\n\u001b[1;32m--> 944\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    947\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DataWhisper\\Datawhisper_venv\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:787\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[1;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n\u001b[0;32m    786\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[1;32m--> 787\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    788\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m    789\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m manager, flattened_output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(run_managers, flattened_outputs):\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DataWhisper\\Datawhisper_venv\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:774\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[1;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[0;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate_helper\u001b[39m(\n\u001b[0;32m    765\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    766\u001b[0m     prompts: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    770\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    771\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    772\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    773\u001b[0m         output \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 774\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    775\u001b[0m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    776\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    777\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[0;32m    778\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    780\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    781\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    782\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(prompts, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[0;32m    783\u001b[0m         )\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    785\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DataWhisper\\Datawhisper_venv\\Lib\\site-packages\\langchain_openai\\llms\\base.py:360\u001b[0m, in \u001b[0;36mBaseOpenAI._generate\u001b[1;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    344\u001b[0m     choices\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m    345\u001b[0m         {\n\u001b[0;32m    346\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: generation\u001b[38;5;241m.\u001b[39mtext,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    357\u001b[0m         }\n\u001b[0;32m    358\u001b[0m     )\n\u001b[0;32m    359\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 360\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_prompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    361\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;66;03m# V1 client returns the response in an PyDantic object instead of\u001b[39;00m\n\u001b[0;32m    363\u001b[0m         \u001b[38;5;66;03m# dict. For the transition period, we deep convert it to dict.\u001b[39;00m\n\u001b[0;32m    364\u001b[0m         response \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mmodel_dump()\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DataWhisper\\Datawhisper_venv\\Lib\\site-packages\\openai\\_utils\\_utils.py:274\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    272\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DataWhisper\\Datawhisper_venv\\Lib\\site-packages\\openai\\resources\\completions.py:528\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, model, prompt, best_of, echo, frequency_penalty, logit_bias, logprobs, max_tokens, n, presence_penalty, seed, stop, stream, stream_options, suffix, temperature, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    526\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    527\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Completion \u001b[38;5;241m|\u001b[39m Stream[Completion]:\n\u001b[1;32m--> 528\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    532\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    534\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbest_of\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    535\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mecho\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mecho\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    536\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    537\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    538\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    539\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    540\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    541\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    542\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    544\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    545\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    546\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msuffix\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    547\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    548\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    549\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    554\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    556\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    558\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mCompletion\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    559\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DataWhisper\\Datawhisper_venv\\Lib\\site-packages\\openai\\_base_client.py:1260\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1246\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1247\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1248\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1255\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1256\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1257\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1258\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1259\u001b[0m     )\n\u001b[1;32m-> 1260\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DataWhisper\\Datawhisper_venv\\Lib\\site-packages\\openai\\_base_client.py:937\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    929\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    930\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    935\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    936\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m--> 937\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    938\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    939\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    940\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DataWhisper\\Datawhisper_venv\\Lib\\site-packages\\openai\\_base_client.py:1041\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1038\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1040\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1041\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1044\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1045\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1049\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39moptions\u001b[38;5;241m.\u001b[39mget_max_retries(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries) \u001b[38;5;241m-\u001b[39m retries,\n\u001b[0;32m   1050\u001b[0m )\n",
      "\u001b[1;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The completion operation does not work with the specified model, gpt-4o. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}"
     ]
    }
   ],
   "source": [
    "llm.invoke(\"Which GPT model am I using ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drl_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
