{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from typing import Any\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.runnables import RunnableLambda, RunnableWithFallbacks\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_community.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.tools import tool\n",
    "from typing import Annotated, Literal\n",
    "\n",
    "from langchain_core.messages import AIMessage\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.graph.message import AnyMessage, add_messages\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# from Sql_prompts import query_check_system\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "\n",
    "def initialize_llm():\n",
    "    aoai_api_key = os.getenv(\"AZURE_OPENAI_API_KEY\") \n",
    "    aoai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "    aoai_api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "    return AzureChatOpenAI(\n",
    "        model=\"gpt-4o\",\n",
    "        deployment_name=\"gpt-4o\",\n",
    "        api_key=aoai_api_key,\n",
    "        azure_endpoint=aoai_endpoint,\n",
    "        api_version=aoai_api_version,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_workflow(db_uri):\n",
    "    db = SQLDatabase.from_uri(db_uri)\n",
    "    llm = initialize_llm()\n",
    "    toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
    "    tools = toolkit.get_tools()\n",
    "    # Define the state for the agent\n",
    "    class State(TypedDict):\n",
    "        messages: Annotated[list[AnyMessage], add_messages]\n",
    "\n",
    "\n",
    "    # Define a new graph\n",
    "    workflow = StateGraph(State)\n",
    "\n",
    "\n",
    "    list_tables_tool = next(tool for tool in tools if tool.name == \"sql_db_list_tables\")\n",
    "    get_schema_tool = next(tool for tool in tools if tool.name == \"sql_db_schema\")\n",
    "\n",
    "    def create_tool_node_with_fallback(tools: list) -> RunnableWithFallbacks[Any, dict]:\n",
    "        \"\"\"\n",
    "        Create a ToolNode with a fallback to handle errors and surface them to the agent.\n",
    "        \"\"\"\n",
    "        return ToolNode(tools).with_fallbacks(\n",
    "            [RunnableLambda(handle_tool_error)], exception_key=\"error\"\n",
    "        )\n",
    "\n",
    "\n",
    "    def handle_tool_error(state) -> dict:\n",
    "        error = state.get(\"error\")\n",
    "        tool_calls = state[\"messages\"][-1].tool_calls\n",
    "        return {\n",
    "            \"messages\": [\n",
    "                ToolMessage(\n",
    "                    content=f\"Error: {repr(error)}\\n please fix your mistakes.\",\n",
    "                    tool_call_id=tc[\"id\"],\n",
    "                )\n",
    "                for tc in tool_calls\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    @tool\n",
    "    def db_query_tool(query: str) -> str:\n",
    "        \"\"\"\n",
    "        Execute a SQL query against the database and get back the result.\n",
    "        If the query is not correct, an error message will be returned.\n",
    "        If an error is returned, rewrite the query, check the query, and try again.\n",
    "        \"\"\"\n",
    "        result = db.run_no_throw(query)\n",
    "        if not result:\n",
    "            return \"Error: Query failed. Please rewrite your query and try again.\"\n",
    "        return result\n",
    "\n",
    "    query_check_system = \"\"\"You are a SQL expert with a strong attention to detail.\n",
    "    Double check the SQLite query for common mistakes, including:\n",
    "    - Using NOT IN with NULL values\n",
    "    - Using UNION when UNION ALL should have been used\n",
    "    - Using BETWEEN for exclusive ranges\n",
    "    - Data type mismatch in predicates\n",
    "    - Properly quoting identifiers\n",
    "    - Using the correct number of arguments for functions\n",
    "    - Casting to the correct data type\n",
    "    - Using the proper columns for joins\n",
    "\n",
    "    Question Interpretation:\n",
    "    - For certain questions, rephrase or expand the query to ensure comprehensive answers:\n",
    "        Example1: \n",
    "        User: \"Show me Sales Performance by country\"\n",
    "        Interpreted as: \"Show me actual sales, Budget, LE (Latest Estimate), by country\"\n",
    "        Example 2:\n",
    "        User:\"Show me market share percentage for DRL for Russia for each brand wise\"\n",
    "        Interpreted as: -Filter data on the country = Russia\n",
    "                        - Group by Product and calculate total DRL Sales and Market Sales\n",
    "                        - Calculate the market share percentage for each product\n",
    "                        - Finally map each product with their brand name\n",
    "\n",
    "    If there are any of the above mistakes, rewrite the query. If there are no mistakes, just reproduce the original query.\n",
    "\n",
    "    You will call the appropriate tool to execute the query after running this check.\"\"\"\n",
    "\n",
    "    query_check_prompt = ChatPromptTemplate.from_messages(\n",
    "        [(\"system\", query_check_system), (\"placeholder\", \"{messages}\")]\n",
    "    )\n",
    "    query_check = query_check_prompt | llm.bind_tools(\n",
    "        [db_query_tool], tool_choice=\"required\"\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    # Add a node for the first tool call\n",
    "    def first_tool_call(state: State) -> dict[str, list[AIMessage]]:\n",
    "        return {\n",
    "            \"messages\": [\n",
    "                AIMessage(\n",
    "                    content=\"\",\n",
    "                    tool_calls=[\n",
    "                        {\n",
    "                            \"name\": \"sql_db_list_tables\",\n",
    "                            \"args\": {},\n",
    "                            \"id\": \"tool_abcd123\",\n",
    "                        }\n",
    "                    ],\n",
    "                )\n",
    "            ]\n",
    "        }\n",
    "\n",
    "\n",
    "    def model_check_query(state: State) -> dict[str, list[AIMessage]]:\n",
    "        \"\"\"\n",
    "        Use this tool to double-check if your query is correct before executing it.\n",
    "        \"\"\"\n",
    "        return {\"messages\": [query_check.invoke({\"messages\": [state[\"messages\"][-1]]})]}\n",
    "\n",
    "\n",
    "    workflow.add_node(\"first_tool_call\", first_tool_call)\n",
    "\n",
    "    # Add nodes for the first two tools\n",
    "    workflow.add_node(\n",
    "        \"list_tables_tool\", create_tool_node_with_fallback([list_tables_tool])\n",
    "    )\n",
    "    workflow.add_node(\"get_schema_tool\", create_tool_node_with_fallback([get_schema_tool]))\n",
    "\n",
    "    # Add a node for a model to choose the relevant tables based on the question and available tables\n",
    "    model_get_schema = llm.bind_tools(\n",
    "        [get_schema_tool]\n",
    "    )\n",
    "    workflow.add_node(\n",
    "        \"model_get_schema\",\n",
    "        lambda state: {\n",
    "            \"messages\": [model_get_schema.invoke(state[\"messages\"])],\n",
    "        },\n",
    "    )\n",
    "\n",
    "\n",
    "    # Describe a tool to represent the end state\n",
    "    class SubmitFinalAnswer(BaseModel):\n",
    "        \"\"\"Submit the final answer to the user based on the query results.\"\"\"\n",
    "\n",
    "        final_answer: str = Field(..., description=\"The final answer to the user\")\n",
    "\n",
    "\n",
    "    # Add a node for a model to generate a query based on the question and schema\n",
    "    query_gen_system = \"\"\"You are a SQL expert with a strong attention to detail.\n",
    "\n",
    "    Given an input question, output a syntactically correct SQLite query to run, then look at the results of the query and return the answer.\n",
    "\n",
    "    DO NOT call any tool besides SubmitFinalAnswer to submit the final answer.\n",
    "\n",
    "    When generating the query:\n",
    "\n",
    "    ENsure Question Interpretation:\n",
    "            - For certain questions, rephrase or expand the query to ensure comprehensive answers:\n",
    "                Example1: \n",
    "                User: \"Show me Sales Performance by country\"\n",
    "                Interpreted as: \"Show me actual sales, Budget, LE (Latest Estimate), by country\"\n",
    "                Example 2:\n",
    "                User:\"Show me market share percentage for DRL for Russia for each brand wise\"\n",
    "                Interpreted as: -Filter data on the country = Russia\n",
    "                                - Group by Product and calculate total DRL Sales and Market Sales\n",
    "                                - Calculate the market share percentage for each product\n",
    "                                - Finally map each product with their brand name\n",
    "\n",
    "    Output the SQL query that answers the input question without a tool call.\n",
    "\n",
    "\n",
    "    You can order the results by a relevant column to return the most interesting examples in the database.\n",
    "    Never query for all the columns from a specific table, only ask for the relevant columns given the question.\n",
    "\n",
    "    If you get an error while executing a query, rewrite the query and try again.\n",
    "\n",
    "    If you get an empty result set, you should try to rewrite the query to get a non-empty result set. \n",
    "    NEVER make stuff up if you don't have enough information to answer the query... just say you don't have enough information.\n",
    "\n",
    "    If you have enough information to answer the input question, simply invoke the appropriate tool to submit the final answer to the user.\n",
    "\n",
    "    DO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\"\"\"\n",
    "    query_gen_prompt = ChatPromptTemplate.from_messages(\n",
    "        [(\"system\", query_gen_system), (\"placeholder\", \"{messages}\")]\n",
    "    )\n",
    "    query_gen = query_gen_prompt | llm.bind_tools(\n",
    "        [SubmitFinalAnswer]\n",
    "    )\n",
    "\n",
    "\n",
    "    def query_gen_node(state: State):\n",
    "        message = query_gen.invoke(state)\n",
    "\n",
    "        # Sometimes, the LLM will hallucinate and call the wrong tool. We need to catch this and return an error message.\n",
    "        tool_messages = []\n",
    "        if message.tool_calls:\n",
    "            for tc in message.tool_calls:\n",
    "                if tc[\"name\"] != \"SubmitFinalAnswer\":\n",
    "                    tool_messages.append(\n",
    "                        ToolMessage(\n",
    "                            content=f\"Error: The wrong tool was called: {tc['name']}. Please fix your mistakes. Remember to only call SubmitFinalAnswer to submit the final answer. Generated queries should be outputted WITHOUT a tool call.\",\n",
    "                            tool_call_id=tc[\"id\"],\n",
    "                        )\n",
    "                    )\n",
    "        else:\n",
    "            tool_messages = []\n",
    "        return {\"messages\": [message] + tool_messages}\n",
    "\n",
    "\n",
    "    workflow.add_node(\"query_gen\", query_gen_node)\n",
    "\n",
    "    # Add a node for the model to check the query before executing it\n",
    "    workflow.add_node(\"correct_query\", model_check_query)\n",
    "\n",
    "    # Add node for executing the query\n",
    "    workflow.add_node(\"execute_query\", create_tool_node_with_fallback([db_query_tool]))\n",
    "\n",
    "\n",
    "    # Define a conditional edge to decide whether to continue or end the workflow\n",
    "    def should_continue(state: State) -> Literal[END, \"correct_query\", \"query_gen\"]:\n",
    "        messages = state[\"messages\"]\n",
    "        last_message = messages[-1]\n",
    "        # If there is a tool call, then we finish\n",
    "        if getattr(last_message, \"tool_calls\", None):\n",
    "            return END\n",
    "        if last_message.content.startswith(\"Error:\"):\n",
    "            return \"query_gen\"\n",
    "        else:\n",
    "            return \"correct_query\"\n",
    "\n",
    "\n",
    "    # Specify the edges between the nodes\n",
    "    workflow.add_edge(START, \"first_tool_call\")\n",
    "    workflow.add_edge(\"first_tool_call\", \"list_tables_tool\")\n",
    "    workflow.add_edge(\"list_tables_tool\", \"model_get_schema\")\n",
    "    workflow.add_edge(\"model_get_schema\", \"get_schema_tool\")\n",
    "    workflow.add_edge(\"get_schema_tool\", \"query_gen\")\n",
    "    workflow.add_conditional_edges(\n",
    "        \"query_gen\",\n",
    "        should_continue,\n",
    "    )\n",
    "    workflow.add_edge(\"correct_query\", \"execute_query\")\n",
    "    workflow.add_edge(\"execute_query\", \"query_gen\")\n",
    "\n",
    "    # Compile the workflow into a runnable\n",
    "    app = workflow.compile()\n",
    "\n",
    "    return app\n",
    "\n",
    "import json\n",
    "def run_sql_agent(db_uri, user_query):\n",
    "    app = create_workflow(db_uri)\n",
    "    messages = app.invoke(\n",
    "        {\"messages\": [(\"user\", prompt)]}\n",
    "    )\n",
    "    json_str = messages[\"messages\"][-1].additional_kwargs[\"tool_calls\"][0][\"function\"][\n",
    "        \"arguments\"\n",
    "    ]\n",
    "    result=json.loads(json_str)[\"final_answer\"]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Sales Performance by country:\n",
       "\n",
       "1. Russia:\n",
       "   - Actual Sales: 84,109,609\n",
       "   - Budget: 86,799,373\n",
       "   - Latest Estimate: 86,659,265\n",
       "\n",
       "2. Brazil:\n",
       "   - Actual Sales: 80,340,019\n",
       "   - Budget: 82,147,309\n",
       "   - Latest Estimate: 82,036,663"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "db=\"sqlite:///csv_data.db\"\n",
    "# prompt=\"Show me Sales Performance by country\"\n",
    "# prompt=\"Show me market share percentage for DRL for Russia brand wise\"\n",
    "# prompt=\"Show me sales by product for FY 2024\"\n",
    "prompt=\"Show me Sales Performance by country\"\n",
    "result=run_sql_agent(db,prompt)\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "display(Markdown(result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drl_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
