{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser, JsonOutputToolsParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent\n",
    "\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain.tools import BaseTool, StructuredTool, tool\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "from pydantic.config import ConfigDict\n",
    "\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py:212: UserWarning: WARNING! deployment_name is not default parameter.\n",
      "                    deployment_name was transferred to model_kwargs.\n",
      "                    Please confirm that deployment_name is what you intended.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 8, 'total_tokens': 17}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_80a1bad4c7', 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {}}, id='run-f26f4e7f-ff3f-46df-8c18-2b4f18ed5c30-0', usage_metadata={'input_tokens': 8, 'output_tokens': 9, 'total_tokens': 17})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "aoai_api_key = os.getenv(\"AZURE_OPENAI_API_KEY\") \n",
    "aoai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "aoai_api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    deployment_name=\"gpt-4o\",\n",
    "    api_key=aoai_api_key,\n",
    "    azure_endpoint=aoai_endpoint,\n",
    "    api_version=aoai_api_version,\n",
    ")\n",
    "\n",
    "\n",
    "# You need to deploy your own embedding model as well as your own chat completion model\n",
    "embed_model = AzureOpenAIEmbeddings(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    deployment_name=\"text-embedding-ada-002\",\n",
    "    api_key=aoai_api_key,\n",
    "    azure_endpoint=aoai_endpoint,\n",
    "    api_version=aoai_api_version,\n",
    ")\n",
    "llm.invoke(\"HI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoquestion(BaseModel):\n",
    "\n",
    "    similar_query:str=Field(\n",
    "        ..., description=\"Get the Similary query to user from the given list of query\")\n",
    "    Index_similar_query:int=Field(\n",
    "        ..., description=\"Index no. of similar question\")\n",
    "    confidence:float =Field(\n",
    "        ..., description=\"confidence score between 0 to 1, of how similar the given user query is th existing list of question\"\n",
    "    )\n",
    "    \n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=Autoquestion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question = \"Show me FY 23 vs FY 24 Performance for brnads in India\"\n",
    "list_Of_exsiting_question = \"\"\"\n",
    "1. Show me FY 2023 vs FY 2024 Performance for top brand in Russia\n",
    "2. show me actual sales, country wise for April 2024 in a table\n",
    "3. brazil performance across years for sales in table\n",
    "4. Country Russia sales achievement % country Product May 2024\n",
    "5. what is the CAGR of Russia sales from fy 2022 to fy2024\n",
    "6. what is the CAGR of Russia\n",
    "7. show me sales for may 2024 vs le vs budget across countries\n",
    "8. Show me list of products where achievement and growth is satisfactory\n",
    "9. budget country Fy2025\n",
    "10. country sales budget Fy2024\n",
    "11. Show me Sales vs Budget vs LE vs PY sales vs sales achievement % vs growth % by country by Brand by Channel for May 2024 in matrix\n",
    "12. Show me the sales russia for month and fy year in matrix\n",
    "13. show me brand by country and achievement% where achievement % is less than 1 in table for April 2024\n",
    "14. Top brand by sales & Budget in Russia for April 2024 in table\n",
    "15.Show sales by Brand classification in matrix by country/brand for FY 2024\n",
    "16. Inhouse vs external sales for FY 2024 in Table\n",
    "17. Show me Sales vs Budget vs LE vs PY sales vs growth % by country by Moleculefor FY 2024 in matrix\n",
    "18 .Show me Sales, sequential value,sequential growth by country for Q1 FY 2024 in matrix\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "template = \"\"\"\n",
    "Your task is to from the give user query match for most similar question from the exitinging list of given question with confidence interval between 0 to 1.\n",
    "\n",
    "FOr Example:\n",
    "#Example-1\n",
    "User query = Show me FY 2023 vs FY 2024 Performance for top brand in Brazil.\n",
    "Similar question= Show me FY 2023 vs FY 2024 Performance for top brand in Russia\n",
    "Index_similar_query=1\n",
    "Confidence= 0.99\n",
    "#Example-2\n",
    "User query = Show me FY 2021 vs FY 2022 Performance for top brand in Brazil.\n",
    "Similar question= Show me FY 2023 vs FY 2024 Performance for top brand in Russia.\n",
    "Index_similar_query=1\n",
    "Confidence= 0.95\n",
    "#Example-3\n",
    "User query = Show me FY 2023 vs FY 2024 Performance for top brand in Russia.\n",
    "Similar question= Show me FY 2023 vs FY 2024 Performance for top brand in Russia.\n",
    "Index_similar_query=1\n",
    "Confidence= 0.99\n",
    "#Example-4\n",
    "User query = Show me FY 2023 vs FY 2024 Performance for top brand in Brazil.\n",
    "Similar question= Show me FY 2023 vs FY 2024 Performance for top brand in Russia.\n",
    "Index_similar_query=1\n",
    "Confidence= 0.99\n",
    "#Example-5\n",
    "User query = what is the CAGR of Brazil sales from fy 22 to fy 24\n",
    "Similar question= what is the CAGR of Russia sales from fy 2022 to fy2024\n",
    "Index_similar_query=5\n",
    "Confidence= 0.95\n",
    "\n",
    "If their is not great match then give low confidence score.\n",
    "\n",
    "User Question: {user_question}\n",
    "List Of Smilar question: {list_Of_exsiting_question}\n",
    "\n",
    "Format Requirement:\n",
    "{format_instructions}\n",
    "                       \n",
    "Answer:\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template= template,\n",
    "    input_variables= [\"user_question\", \"list_Of_exsiting_questiont_answer\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "answer = chain.invoke({\"user_question\": user_question ,\"list_Of_exsiting_question\": list_Of_exsiting_question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'similar_query': 'Show me FY 2023 vs FY 2024 Performance for top brand in Russia',\n",
       " 'Index_similar_query': 1,\n",
       " 'confidence': 0.95}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class MainState(TypedDict):\n",
    "\n",
    "    question:str\n",
    "    similar_query:str\n",
    "    Index_similar_query:int\n",
    "    confidence:float\n",
    "    \n",
    "graph_builder = StateGraph(MainState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoquestion(BaseModel):\n",
    "\n",
    "    similar_query:str=Field(\n",
    "        ..., description=\"Get the Similary query to user from the given list of query\")\n",
    "    Index_similar_query:int=Field(\n",
    "        ..., description=\"Index no. of similar question\")\n",
    "    confidence:float =Field(\n",
    "        ..., description=\"confidence score between 0 to 1, of how similar the given user query is th existing list of question\"\n",
    "    )\n",
    "\n",
    "def query_check(state:MainState):\n",
    "    aoai_api_key = os.getenv(\"AZURE_OPENAI_API_KEY\") \n",
    "    aoai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "    aoai_api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "    llm = AzureChatOpenAI(\n",
    "        model=\"gpt-4o\",\n",
    "        deployment_name=\"gpt-4o\",\n",
    "        api_key=aoai_api_key,\n",
    "        azure_endpoint=aoai_endpoint,\n",
    "        api_version=aoai_api_version,\n",
    "    )\n",
    "\n",
    "\n",
    "    # You need to deploy your own embedding model as well as your own chat completion model\n",
    "    embed_model = AzureOpenAIEmbeddings(\n",
    "        model=\"text-embedding-ada-002\",\n",
    "        deployment_name=\"text-embedding-ada-002\",\n",
    "        api_key=aoai_api_key,\n",
    "        azure_endpoint=aoai_endpoint,\n",
    "        api_version=aoai_api_version,\n",
    "    )\n",
    "  \n",
    "\n",
    "       \n",
    "\n",
    "    parser = JsonOutputParser(pydantic_object=Autoquestion)\n",
    "    # message\n",
    "    # user_question = \"Show me FY 23 vs FY 24 Performance for brnads in India\"\n",
    "    user_question = state['question']\n",
    "    list_Of_exsiting_question = \"\"\"\n",
    "    1. Show me FY 2023 vs FY 2024 Performance for top brand in Russia\n",
    "    2. show me actual sales, country wise for April 2024 in a table\n",
    "    3. brazil performance across years for sales in table\n",
    "    4. Country Russia sales achievement % country Product May 2024\n",
    "    5. what is the CAGR of Russia sales from fy 2022 to fy2024\n",
    "    6. what is the CAGR of Russia\n",
    "    7. show me sales for may 2024 vs le vs budget across countries\n",
    "    8. Show me list of products where achievement and growth is satisfactory\n",
    "    9. budget country Fy2025\n",
    "    10. country sales budget Fy2024\n",
    "    11. Show me Sales vs Budget vs LE vs PY sales vs sales achievement % vs growth % by country by Brand by Channel for May 2024 in matrix\n",
    "    12. Show me the sales russia for month and fy year in matrix\n",
    "    13. show me brand by country and achievement% where achievement % is less than 1 in table for April 2024\n",
    "    14. Top brand by sales & Budget in Russia for April 2024 in table\n",
    "    15.Show sales by Brand classification in matrix by country/brand for FY 2024\n",
    "    16. Inhouse vs external sales for FY 2024 in Table\n",
    "    17. Show me Sales vs Budget vs LE vs PY sales vs growth % by country by Moleculefor FY 2024 in matrix\n",
    "    18 .Show me Sales, sequential value,sequential growth by country for Q1 FY 2024 in matrix\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    template = \"\"\"\n",
    "    Your task is to from the give user query match for most similar question from the exitinging list of given question with confidence interval between 0 to 1.\n",
    "\n",
    "    FOr Example:\n",
    "    #Example-1\n",
    "    User query = Show me FY 2023 vs FY 2024 Performance for top brand in Brazil.\n",
    "    Similar question= Show me FY 2023 vs FY 2024 Performance for top brand in Russia\n",
    "    Index_similar_query=1\n",
    "    Confidence= 0.99\n",
    "    #Example-2\n",
    "    User query = Show me FY 2021 vs FY 2022 Performance for top brand in Brazil.\n",
    "    Similar question= Show me FY 2023 vs FY 2024 Performance for top brand in Russia.\n",
    "    Index_similar_query=1\n",
    "    Confidence= 0.95\n",
    "    #Example-3\n",
    "    User query = Show me FY 2023 vs FY 2024 Performance for top brand in Russia.\n",
    "    Similar question= Show me FY 2023 vs FY 2024 Performance for top brand in Russia.\n",
    "    Index_similar_query=1\n",
    "    Confidence= 0.99\n",
    "    #Example-4\n",
    "    User query = Show me FY 2023 vs FY 2024 Performance for top brand in Brazil.\n",
    "    Similar question= Show me FY 2023 vs FY 2024 Performance for top brand in Russia.\n",
    "    Index_similar_query=1\n",
    "    Confidence= 0.99\n",
    "    #Example-5\n",
    "    User query = what is the CAGR of Brazil sales from fy 22 to fy 24\n",
    "    Similar question= what is the CAGR of Russia sales from fy 2022 to fy2024\n",
    "    Index_similar_query=5\n",
    "    Confidence= 0.95\n",
    "\n",
    "    If their is not great match then give low confidence score.\n",
    "\n",
    "    User Question: {user_question}\n",
    "    List Of Smilar question: {list_Of_exsiting_question}\n",
    "\n",
    "    Format Requirement:\n",
    "    {format_instructions}\n",
    "                        \n",
    "    Answer:\n",
    "\n",
    "    \"\"\"\n",
    "    prompt = PromptTemplate(\n",
    "    template= template,\n",
    "    input_variables= [\"user_question\", \"list_Of_exsiting_questiont_answer\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "    chain = prompt | llm | parser\n",
    "\n",
    "    answer = chain.invoke({\"user_question\": user_question ,\"list_Of_exsiting_question\": list_Of_exsiting_question})\n",
    "    \n",
    "    state['similar_query']=answer['similar_query']\n",
    "    state['Index_similar_query']=answer['Index_similar_query']\n",
    "    state['confidence']=answer['confidence']\n",
    "\n",
    "    return state\n",
    "  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()\n",
    "builder = StateGraph(MainState)\n",
    "# def query_check(state:MainState):\n",
    "builder.add_node(\"chatbot\",query_check )\n",
    "\n",
    "# builder.add_node(\"router\", router_node)\n",
    "\n",
    "builder.set_entry_point(\"chatbot\")\n",
    "builder.add_edge('chatbot', END)\n",
    "\n",
    "# graph = builder.compile(checkpointer=memory)\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py:212: UserWarning: WARNING! deployment_name is not default parameter.\n",
      "                    deployment_name was transferred to model_kwargs.\n",
      "                    Please confirm that deployment_name is what you intended.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chatbot': {'question': 'Does LangChain support Ollama?', 'similar_query': 'what is the CAGR of Russia', 'Index_similar_query': 6, 'confidence': 0.3}}\n"
     ]
    }
   ],
   "source": [
    "# result = graph.invoke({'question', user_question})\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for s in graph.stream({\n",
    "    'question': \"Does LangChain support Ollama?\",\n",
    "}, thread):\n",
    "    print(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py:212: UserWarning: WARNING! deployment_name is not default parameter.\n",
      "                    deployment_name was transferred to model_kwargs.\n",
      "                    Please confirm that deployment_name is what you intended.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Does LangChain support Ollama?',\n",
       " 'similar_query': 'what is the CAGR of Russia',\n",
       " 'Index_similar_query': 6,\n",
       " 'confidence': 0.3}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = graph.invoke({'question': \"Does LangChain support Ollama?\"})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py:212: UserWarning: WARNING! deployment_name is not default parameter.\n",
      "                    deployment_name was transferred to model_kwargs.\n",
      "                    Please confirm that deployment_name is what you intended.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chatbot': {'question': 'Show me FY 23 vs FY 24 Performance for brnads in India', 'similar_query': 'Show me FY 2023 vs FY 2024 Performance for top brand in Russia', 'Index_similar_query': 1, 'confidence': 0.95}}\n"
     ]
    }
   ],
   "source": [
    "user_question = \"Show me FY 23 vs FY 24 Performance for brnads in India\"\n",
    "# config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for s in graph.stream({\n",
    "    'question': user_question,\n",
    "}, thread):\n",
    "    print(s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py:212: UserWarning: WARNING! deployment_name is not default parameter.\n",
      "                    deployment_name was transferred to model_kwargs.\n",
      "                    Please confirm that deployment_name is what you intended.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser, JsonOutputToolsParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent\n",
    "\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain.tools import BaseTool, StructuredTool, tool\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "from pydantic.config import ConfigDict\n",
    "\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "\n",
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = \"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\"\n",
    "\n",
    "aoai_api_key = os.getenv(\"AZURE_OPENAI_API_KEY\") \n",
    "aoai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "aoai_api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    deployment_name=\"gpt-4o\",\n",
    "    api_key=aoai_api_key,\n",
    "    azure_endpoint=aoai_endpoint,\n",
    "    api_version=aoai_api_version,\n",
    ")\n",
    "\n",
    "# llm = ChatOpenAI(temperature=0, model=\"gpt-4\")\n",
    "\n",
    "# You need to deploy your own embedding model as well as your own chat completion model\n",
    "embed_model = AzureOpenAIEmbeddings(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    deployment_name=\"text-embedding-ada-002\",\n",
    "    api_key=aoai_api_key,\n",
    "    azure_endpoint=aoai_endpoint,\n",
    "    api_version=aoai_api_version,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# LANGGRAPH\n",
    "class MainState(TypedDict):\n",
    "\n",
    "    question:str\n",
    "    similar_query:str\n",
    "    Index_similar_query:int\n",
    "    confidence:float\n",
    "    \n",
    "graph_builder = StateGraph(MainState)\n",
    "\n",
    "class Autoquestion(BaseModel):\n",
    "\n",
    "    similar_query:str=Field(\n",
    "        ..., description=\"Get the Similary query to user from the given list of query\")\n",
    "    Index_similar_query:int=Field(\n",
    "        ..., description=\"Index no. of similar question\")\n",
    "    confidence:float =Field(\n",
    "        ..., description=\"confidence score between 0 to 1, of how similar the given user query is th existing list of question\"\n",
    "    )\n",
    "\n",
    "def query_check(state:MainState):\n",
    "    # aoai_api_key = os.getenv(\"AZURE_OPENAI_API_KEY\") \n",
    "    # aoai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "    # aoai_api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "    \n",
    "\n",
    "    parser = JsonOutputParser(pydantic_object=Autoquestion)\n",
    "    # message\n",
    "    # user_question = \"Show me FY 23 vs FY 24 Performance for brnads in India\"\n",
    "    user_question = state['question']\n",
    "    list_Of_exsiting_question = \"\"\"\n",
    "    1. Show me FY 2023 vs FY 2024 Performance for top brand in Russia\n",
    "    2. show me actual sales, country wise for April 2024 in a table\n",
    "    3. brazil performance across years for sales in table\n",
    "    4. Country Russia sales achievement % country Product May 2024\n",
    "    5. what is the CAGR of Russia sales from fy 2022 to fy2024\n",
    "    6. what is the CAGR of Russia\n",
    "    7. show me sales for may 2024 vs le vs budget across countries\n",
    "    8. Show me list of products where achievement and growth is satisfactory\n",
    "    9. budget country Fy2025\n",
    "    10. country sales budget Fy2024\n",
    "    11. Show me Sales vs Budget vs LE vs PY sales vs sales achievement % vs growth % by country by Brand by Channel for May 2024 in matrix\n",
    "    12. Show me the sales russia for month and fy year in matrix\n",
    "    13. show me brand by country and achievement% where achievement % is less than 1 in table for April 2024\n",
    "    14. Top brand by sales & Budget in Russia for April 2024 in table\n",
    "    15.Show sales by Brand classification in matrix by country/brand for FY 2024\n",
    "    16. Inhouse vs external sales for FY 2024 in Table\n",
    "    17. Show me Sales vs Budget vs LE vs PY sales vs growth % by country by Moleculefor FY 2024 in matrix\n",
    "    18 .Show me Sales, sequential value,sequential growth by country for Q1 FY 2024 in matrix\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    template = \"\"\"\n",
    "    Your task is to from the give user query match for most similar question from the exitinging list of given question with confidence interval between 0 to 1.\n",
    "\n",
    "    FOr Example:\n",
    "    #Example-1\n",
    "    User query = Show me FY 2023 vs FY 2024 Performance for top brand in Brazil.\n",
    "    Similar question= Show me FY 2023 vs FY 2024 Performance for top brand in Russia\n",
    "    Index_similar_query=1\n",
    "    Confidence= 0.99\n",
    "    #Example-2\n",
    "    User query = Show me FY 2021 vs FY 2022 Performance for top brand in Brazil.\n",
    "    Similar question= Show me FY 2023 vs FY 2024 Performance for top brand in Russia.\n",
    "    Index_similar_query=1\n",
    "    Confidence= 0.95\n",
    "    #Example-3\n",
    "    User query = Show me FY 2023 vs FY 2024 Performance for top brand in Russia.\n",
    "    Similar question= Show me FY 2023 vs FY 2024 Performance for top brand in Russia.\n",
    "    Index_similar_query=1\n",
    "    Confidence= 0.99\n",
    "    #Example-4\n",
    "    User query = Show me FY 2023 vs FY 2024 Performance for top brand in Brazil.\n",
    "    Similar question= Show me FY 2023 vs FY 2024 Performance for top brand in Russia.\n",
    "    Index_similar_query=1\n",
    "    Confidence= 0.99\n",
    "    #Example-5\n",
    "    User query = what is the CAGR of Brazil sales from fy 22 to fy 24\n",
    "    Similar question= what is the CAGR of Russia sales from fy 2022 to fy2024\n",
    "    Index_similar_query=5\n",
    "    Confidence= 0.95\n",
    "\n",
    "    If you find confidence scroe to be <=0.40 then mark \"Similar question\"=\"NONE\n",
    "    Index_similar_query=0\n",
    "    Confidence=0\n",
    "\n",
    "    User Question: {user_question}\n",
    "    List Of Smilar question: {list_Of_exsiting_question}\n",
    "\n",
    "    Format Requirement:\n",
    "    {format_instructions}\n",
    "                        \n",
    "    Answer:\n",
    "\n",
    "    \"\"\"\n",
    "    prompt = PromptTemplate(\n",
    "    template= template,\n",
    "    input_variables= [\"user_question\", \"list_Of_exsiting_questiont_answer\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "    chain = prompt | llm | parser\n",
    "\n",
    "    answer = chain.invoke({\"user_question\": user_question ,\"list_Of_exsiting_question\": list_Of_exsiting_question})\n",
    "    \n",
    "    state['similar_query']=answer['similar_query']\n",
    "    state['Index_similar_query']=answer['Index_similar_query']\n",
    "    state['confidence']=answer['confidence']\n",
    "\n",
    "    return state\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def query_check_agent(user_query,thread_id_no):\n",
    "def query_check_agent(user_query):\n",
    "\n",
    "    memory = MemorySaver()\n",
    "    builder = StateGraph(MainState)\n",
    "    builder.add_node(\"chatbot\",query_check )\n",
    "    builder.set_entry_point(\"chatbot\")\n",
    "    builder.add_edge('chatbot', END)\n",
    "    # graph = builder.compile(checkpointer=memory)\n",
    "    graph = builder.compile()\n",
    "\n",
    "\n",
    "    # thread = {\"configurable\": {\"thread_id\": str(thread_id_no)}}\n",
    "    \n",
    "    # for s in graph.stream({ 'question': user_query,}, thread):\n",
    "    #     print(s)\n",
    "    \n",
    "    # current_state = graph.get_state(thread)\n",
    "    current_state = graph.invoke({'question': user_query})\n",
    "    return current_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt=\"What is langchain\"\n",
    "prompt=\"Show me achievement% by country for each brand in FY 2024\"\n",
    "q_b = query_check_agent(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Show me achievement% by country for each brand in FY 2024',\n",
       " 'similar_query': 'Show sales by Brand classification in matrix by country/brand for FY 2024',\n",
       " 'Index_similar_query': 15,\n",
       " 'confidence': 0.85}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dict Datastrcuture question bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py:212: UserWarning: WARNING! deployment_name is not default parameter.\n",
      "                    deployment_name was transferred to model_kwargs.\n",
      "                    Please confirm that deployment_name is what you intended.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "aoai_api_key = os.getenv(\"AZURE_OPENAI_API_KEY\") \n",
    "aoai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "aoai_api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    deployment_name=\"gpt-4o\",\n",
    "    api_key=aoai_api_key,\n",
    "    azure_endpoint=aoai_endpoint,\n",
    "    api_version=aoai_api_version,\n",
    ")\n",
    "\n",
    "\n",
    "# You need to deploy your own embedding model as well as your own chat completion model\n",
    "embed_model = AzureOpenAIEmbeddings(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    # deployment_name=\"text-embedding-ada-002\",\n",
    "    api_key=aoai_api_key,\n",
    "    azure_endpoint=aoai_endpoint,\n",
    "    api_version=aoai_api_version,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "import numpy as np\n",
    "\n",
    "# Sample data structure\n",
    "question_data  = [\n",
    "    {\n",
    "        \"Id\": 1,\n",
    "        \"Question\": \"Show me FY 2023 vs FY 2024 Performance for top brand in Russia\",\n",
    "        \"Described Steps\": \"1. Retrieve data for top brand in Russia for FY 2023 and FY 2024\\n2. Compare the performance metrics (e.g., sales, market share, growth rate) between the two fiscal years\\n3. Present the results in a clear and concise format\"\n",
    "    },\n",
    "    {\n",
    "        \"Id\": 2,\n",
    "        \"Question\": \"Show me actual sales, country wise for April 2024 in a table\",\n",
    "        \"Described Steps\": \"1. Gather sales data for all countries for April 2024\\n2. Organize the data in a tabular format, with countries as rows and sales figures as columns\\n3. Present the table in a clear and readable manner\"\n",
    "    },\n",
    "    {\n",
    "        \"Id\": 3,\n",
    "        \"Question\": \"Brazil performance across years for sales in table\",\n",
    "        \"Described Steps\": \"1. Collect sales data for Brazil over multiple fiscal years (e.g., FY 2022, FY 2023, FY 2024)\\n2. Arrange the data in a table format, with fiscal years as rows and sales figures as columns\\n3. Include any relevant performance metrics (e.g., growth rate) in the table\"\n",
    "    },\n",
    "    {\n",
    "        \"Id\": 4,\n",
    "        \"Question\": \"Country Russia sales achievement % country Product May 2024\",\n",
    "        \"Described Steps\": \"1. Obtain sales data for Russia, broken down by product, for May 2024\\n2. Calculate the sales achievement percentage for each product compared to the target or budget\\n3. Present the results in a table format, with products as rows and sales achievement percentage as the column\"\n",
    "    },\n",
    "    {\n",
    "        \"Id\": 5,\n",
    "        \"Question\": \"What is the CAGR of Russia sales from FY 2022 to FY 2024\",\n",
    "        \"Described Steps\": \"1. Gather sales data for Russia from FY 2022 to FY 2024\\n2. Calculate the Compound Annual Growth Rate (CAGR) of Russia sales over this period\\n3. Present the CAGR value, along with the formula used and any relevant context\"\n",
    "    },\n",
    "    {\n",
    "        \"Id\": 6,\n",
    "        \"Question\": \"What is the CAGR of Russia\",\n",
    "        \"Described Steps\": \"1. Gather sales data for Russia over multiple fiscal years\\n2. Calculate the Compound Annual Growth Rate (CAGR) of Russia sales over the selected time period\\n3. Present the CAGR value, along with the formula used and any relevant context\"\n",
    "    },\n",
    "    {\n",
    "        \"Id\": 7,\n",
    "        \"Question\": \"Show me sales for May 2024 vs LE vs budget across countries\",\n",
    "        \"Described Steps\": \"1. Collect sales data for May 2024, along with the latest estimate (LE) and the budget, for all countries\\n2. Organize the data in a table format, with countries as rows and the different metrics (May 2024 sales, LE, budget) as columns\\n3. Present the table in a clear and readable manner\"\n",
    "    },\n",
    "    {\n",
    "        \"Id\": 8,\n",
    "        \"Question\": \"Show me list of products where achievement and growth is satisfactory\",\n",
    "        \"Described Steps\": \"1. Gather data on product performance, including sales achievement and growth, for the relevant time period\\n2. Identify the products where both the sales achievement and growth are considered satisfactory based on predefined criteria\\n3. Present the list of these products in a clear and organized manner\"\n",
    "    },\n",
    "    {\n",
    "        \"Id\": 9,\n",
    "        \"Question\": \"Budget country FY 2025\",\n",
    "        \"Described Steps\": \"1. Collect the budgeted sales figures for each country for the upcoming fiscal year (FY 2025)\\n2. Organize the data in a table or matrix format, with countries as rows and the budgeted sales as the column\\n3. Present the information in a clear and concise way\"\n",
    "    },\n",
    "    {\n",
    "        \"Id\": 10,\n",
    "        \"Question\": \"Country sales budget FY 2024\",\n",
    "        \"Described Steps\": \"1. Gather the budgeted sales figures for each country for the current fiscal year (FY 2024)\\n2. Arrange the data in a table or matrix format, with countries as rows and the budgeted sales as the column\\n3. Present the information in a clear and concise way\"\n",
    "    },\n",
    "    {\n",
    "        \"Id\": 11,\n",
    "        \"Question\": \"Show me Sales vs Budget vs LE vs PY sales vs sales achievement % vs growth % by country by Brand by Channel for May 2024 in matrix\",\n",
    "        \"Described Steps\": \"1. Collect the following data for May 2024: sales, budget, latest estimate (LE), prior year (PY) sales, sales achievement percentage, and growth percentage\\n2. Organize the data in a matrix format, with countries as rows, brands as columns, and the different metrics as the cells\\n3. Present the matrix in a clear and comprehensive manner\"\n",
    "    },\n",
    "    {\n",
    "        \"Id\": 12,\n",
    "        \"Question\": \"Show me the sales Russia for month and FY year in matrix\",\n",
    "        \"Described Steps\": \"1. Gather the sales data for Russia, broken down by month and fiscal year\\n2. Arrange the data in a matrix format, with months as rows and fiscal years as columns\\n3. Present the matrix in a clear and readable way\"\n",
    "    },\n",
    "    {\n",
    "        \"Id\": 13,\n",
    "        \"Question\": \"Show me brand by country and achievement % where achievement % is less than 1 in table for April 2024\",\n",
    "        \"Described Steps\": \"1. Collect the brand-level sales data for each country, along with the corresponding sales achievement percentage, for April 2024\\n2. Filter the data to include only the brands where the sales achievement percentage is less than 1 (100%)\\n3. Organize the filtered data in a table format, with countries as rows, brands as columns, and the sales achievement percentage as the values\"\n",
    "    },\n",
    "    {\n",
    "        \"Id\": 14,\n",
    "        \"Question\": \"Top brand by sales & Budget in Russia for April 2024 in table\",\n",
    "        \"Described Steps\": \"1. Identify the top brand in Russia based on sales and budget for April 2024\\n2. Gather the sales and budget figures for the top brand\\n3. Present the information in a table format, with the brand name, sales, and budget as the columns\"\n",
    "    },\n",
    "    {\n",
    "        \"Id\": 15,\n",
    "        \"Question\": \"Show sales by Brand classification in matrix by country/brand for FY 2024\",\n",
    "        \"Described Steps\": \"1. Classify the brands into relevant categories (e.g., premium, mass market, etc.)\\n2. Collect the sales data for each brand classification, broken down by country, for the FY 2024\\n3. Organize the data in a matrix format, with countries as rows, brand classifications as columns, and the sales figures as the values\"\n",
    "    },\n",
    "    {\n",
    "        \"Id\": 16,\n",
    "        \"Question\": \"Inhouse vs external sales for FY 2024 in Table\",\n",
    "        \"Described Steps\": \"1. Gather the sales data for FY 2024, distinguishing between in-house and external (e.g., distributor, partner) sales\\n2. Arrange the data in a table format, with the sales channel (in-house, external) as rows and the sales figures as the column\"\n",
    "    },\n",
    "    {\n",
    "        \"Id\": 17,\n",
    "        \"Question\": \"Show me Sales vs Budget vs LE vs PY sales vs growth % by country by Molecule for FY 2024 in matrix\",\n",
    "        \"Described Steps\": \"1. Collect the following data for FY 2024: sales, budget, latest estimate (LE), prior year (PY) sales, and growth percentage\\n2. Organize the data in a matrix format, with countries as rows, molecules (or products) as columns, and the different metrics as the cells\\n3. Present the matrix in a clear and comprehensive manner\"\n",
    "    },\n",
    "    {\n",
    "        \"Id\": 18,\n",
    "        \"Question\": \"Show me Sales, sequential value, sequential growth by country for Q1 FY 2024 in matrix\",\n",
    "        \"Described Steps\": \"1. Gather the sales data for Q1 of FY 2024, broken down by country\\n2. Calculate the sequential value (previous period's value) and sequential growth for each country\\n3. Arrange the sales, sequential value, and sequential growth data in a matrix format, with countries as rows and the different metrics as columns\"\n",
    "    }\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Embeddings.create() got an unexpected keyword argument 'deployment_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m question_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43membed_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mq\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mQuestion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mquestion_data\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mlen\u001b[39m(question_embeddings)\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py:558\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_documents\u001b[1;34m(self, texts, chunk_size)\u001b[0m\n\u001b[0;32m    555\u001b[0m \u001b[38;5;66;03m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[0;32m    556\u001b[0m \u001b[38;5;66;03m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[0;32m    557\u001b[0m engine \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeployment)\n\u001b[1;32m--> 558\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_len_safe_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py:456\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[1;34m(self, texts, engine, chunk_size)\u001b[0m\n\u001b[0;32m    454\u001b[0m batched_embeddings: List[List[\u001b[38;5;28mfloat\u001b[39m]] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m _iter:\n\u001b[1;32m--> 456\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokens\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_chunk_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invocation_params\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    459\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    460\u001b[0m         response \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mmodel_dump()\n",
      "\u001b[1;31mTypeError\u001b[0m: Embeddings.create() got an unexpected keyword argument 'deployment_name'"
     ]
    }
   ],
   "source": [
    "question_embeddings = embed_model.embed_documents([q[\"Question\"] for q in question_data])\n",
    "len(question_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    " \n",
    "\n",
    "class QuestionProcessor:\n",
    "    def __init__(self, question_data):\n",
    "        self.question_data = question_data\n",
    "        self.embedder = embed_model\n",
    "        self.question_embeddings = self.embedder.embed_documents([q[\"Question\"] for q in self.question_data])\n",
    "\n",
    "    def find_similar_questions(self, query, top_n=3):\n",
    "        query_embedding = self.embedder.embed_query(query)\n",
    "        similarities = np.dot(query_embedding, np.array(self.question_embeddings).T)\n",
    "        top_indices = similarities.argsort()[-top_n:][::-1]\n",
    "        \n",
    "        results = []\n",
    "        for i in top_indices:\n",
    "            results.append({\n",
    "                \"Id\": self.question_data[i][\"Id\"],\n",
    "                \"Question\": self.question_data[i][\"Question\"],\n",
    "                \"Described Steps\": self.question_data[i][\"Described Steps\"],\n",
    "                \"Confidence\": similarities[i]\n",
    "            })\n",
    "        \n",
    "        return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'question_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m processor \u001b[38;5;241m=\u001b[39m QuestionProcessor(\u001b[43mquestion_data\u001b[49m)\n\u001b[0;32m      3\u001b[0m user_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhat is the performance of brazil ?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m similar_questions \u001b[38;5;241m=\u001b[39m processor\u001b[38;5;241m.\u001b[39mfind_similar_questions(user_query)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'question_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "processor = QuestionProcessor(question_data)\n",
    "user_query = \"what is the performance of brazil ?\"\n",
    "similar_questions = processor.find_similar_questions(user_query)\n",
    "\n",
    "for q in similar_questions:\n",
    "    print(f\"Id: {q['Id']}\")\n",
    "    print(f\"Question: {q['Question']}\")\n",
    "    print(f\"Described Steps: {q['Described Steps']}\")\n",
    "    print(f\"Confidence: {q['Confidence']:.2f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic Few Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'SemanticSimilarityExampleSelector' from 'langchain_core.prompts' (c:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\langchain_core\\prompts\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SemanticSimilarityExampleSelector\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAIEmbeddings\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvectorstores\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Chroma\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'SemanticSimilarityExampleSelector' from 'langchain_core.prompts' (c:\\Users\\skaushik047\\Desktop\\WORK\\DRL\\V2\\Excel_LLM\\drl_venv\\Lib\\site-packages\\langchain_core\\prompts\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import SemanticSimilarityExampleSelector\n",
    "from langchain_core.embeddings import OpenAIEmbeddings\n",
    "from langchain_core.vectorstores import Chroma\n",
    "\n",
    "from langchain_core import SystemMessage\n",
    "from langchain_core.prompts import HumanMessagePromptTemplate\n",
    "from langchain_core.prompts.few_shot import FewShotChatMessagePromptTemplate\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "aoai_api_key = os.getenv(\"AZURE_OPENAI_API_KEY\") \n",
    "aoai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "aoai_api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    deployment_name=\"gpt-4o\",\n",
    "    api_key=aoai_api_key,\n",
    "    azure_endpoint=aoai_endpoint,\n",
    "    api_version=aoai_api_version,\n",
    ")\n",
    "\n",
    "\n",
    "# You need to deploy your own embedding model as well as your own chat completion model\n",
    "embed_model = AzureOpenAIEmbeddings(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    deployment_name=\"text-embedding-ada-002\",\n",
    "    api_key=aoai_api_key,\n",
    "    azure_endpoint=aoai_endpoint,\n",
    "    api_version=aoai_api_version,\n",
    ")\n",
    "llm.invoke(\"HI\")\n",
    "\n",
    "examples =question_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "to_vectorize = [\n",
    "    \" \".join(example.values())\n",
    "    for example in examples\n",
    "]\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = Chroma.from_texts(\n",
    "    to_vectorize, embeddings, metadatas=examples\n",
    ")\n",
    "example_selector = SemanticSimilarityExampleSelector(\n",
    "    vectorstore=vectorstore\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    # Which variable(s) will be passed to the example selector.\n",
    "    input_variables=[\"input\"],\n",
    "    example_selector=example_selector,\n",
    "    # Define how each example will be formatted.\n",
    "    # In this case, each example will become 2 messages:\n",
    "    # 1 human, and 1 AI\n",
    "    example_prompt=(\n",
    "        HumanMessagePromptTemplate.from_template(\"{input}\")\n",
    "        + AIMessagePromptTemplate.from_template(\"{output}\")\n",
    "    ),\n",
    ")\n",
    "# Define the overall prompt.\n",
    "final_prompt = (\n",
    "    SystemMessagePromptTemplate.from_template(\n",
    "        \"You are a helpful AI Assistant\"\n",
    "    )\n",
    "    + few_shot_prompt\n",
    "    + HumanMessagePromptTemplate.from_template(\"{input}\")\n",
    ")\n",
    "# Show the prompt\n",
    "print(final_prompt.format_messages(input=\"What's 3+3?\"))  # noqa: T201\n",
    "\n",
    "# Use within an LLM\n",
    "from langchain_core.chat_models import ChatAnthropic\n",
    "chain = final_prompt | ChatAnthropic(model=\"claude-3-haiku-20240307\")\n",
    "chain.invoke({\"input\": \"What's 3+3?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drl_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
